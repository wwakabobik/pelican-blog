<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>wwakabobik's lair - wwakabobik</title><link href="https://wwakabobik.github.io/" rel="alternate"></link><link href="https://wwakabobik.github.io/feeds/wwakabobik.author.atom.xml" rel="self"></link><id>https://wwakabobik.github.io/</id><updated>2023-10-23T09:38:00+02:00</updated><entry><title>AI practices used for QA</title><link href="https://wwakabobik.github.io/2023/10/qa_ai_practices_used_for_qa/" rel="alternate"></link><published>2023-10-23T09:38:00+02:00</published><updated>2023-10-23T08:35:50+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-10-23:/2023/10/qa_ai_practices_used_for_qa/</id><summary type="html">&lt;p class="first last"&gt;Can AI completely replace human testers? Is it more than tool? What are the best practices for using AI in QA? Let's find out!&lt;/p&gt;
</summary><content type="html">&lt;p&gt;As a beginning, I want say that LLM is a great base for introducing to any field or subject and the QA is no exception. AI does an excellent job of explaining testing theory; it can interactively explain the best practices, share the knowledge and accumulated past experience, recommend the QA-related books, answer questions and help a Junior tester to dive into QA area. If so, then a reasonable question arises: can AI completely replace the tester? And this question is ambiguous. Considering the pace of AI development, the answer is yes, on the other hand, there are several pitfalls and nuances…&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/hNtOEr2W2D4?si=FpdFJ1VDOk8PBO4W" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;&lt;div class="section" id="manual-testing-and-possibilities"&gt;
&lt;h2&gt;Manual testing and possibilities&lt;/h2&gt;
&lt;p&gt;I use AI assistants every day in my work. And I may say that now the capabilities of AI are comparable to several Junior testers at once. Existing AIs can perform very well of what young testers can do being under control of the Senior. Let's say, depending on the AI model, and how you use it, AI can handle tasks of a manual tester very well, like write checklists or troubleshooting, and act as a test designer - describe test cases in details. But with the nuance that you, as a Senior tester, still need to control and correct it, and, what is most importantly, have a good understanding of your subject area. The fact is that AI can perform a task quite well and put it in layman's terms, in the most understandable and obvious way. This means you shouldn’t expect complex interconnected and, most importantly, deep nested scenarios from AI.&lt;/p&gt;
&lt;img alt="LLM generates code for you" src="/assets/images/articles/qa/ai_practices_used_for_qa/pom_generation.jpg" /&gt;
&lt;p&gt;Don’t expect that it will separate test data from test cases (although it knows perfectly well how to do it right). So, every time you will need to adjust AI and its outputs: redo it, complete it, deepen it. Tell again and again: rework, rework, rework, show me an several options, retry… And every time you will confront a problem, that consistency of cases is because of size limitation of the context: the data and instructions with which your AI works. This is similar to how to train a Junior tester to fit you, to fit your vision, to fit the depth and accuracy, style you need, to fit your capabilities and cost - in terms of money and time and productivity. And due to this you need to provide the context before generation each time, or retrain the model to suit your specific needs (substitute embeddings, fine-tune models, etc.). In other words, without a lot of context, giving some tasks to AI, which can be done by Middle tester, won’t work at all. Because AI doesn’t have enough context and a control mechanism, some feedback loop, thus, you must control it every and each interaction. But we can try to delegate control also… But let’s not hurry for now.&lt;/p&gt;
&lt;img alt="LLM generates code for you" src="/assets/images/articles/qa/ai_practices_used_for_qa/checklists.jpg" /&gt;
&lt;p&gt;At the same time, AI is not just a tool for delegating routine, but it also your helpful assistant and handy reference, deeply involved in solving your problems. Give it a log, an error, a problem or ask how to set up some environment or tool, and the AI will do the its task quickly and perfectly, without human being need to google StackOverflow. But you need to understand that most models are relevant for a certain date of training, and model will not know about changes made in recent weeks, months, or even a year. Unless, of course, it has access to Internet search.&lt;/p&gt;
&lt;img alt="Environment setup guide" src="/assets/images/articles/qa/ai_practices_used_for_qa/env_guide.jpg" /&gt;
&lt;p&gt;Further I'll move on to automated testing only. Cause actual thing performed by AI is automation of every routine you may have. So, what do I personally use AI for and what kind?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="copilot"&gt;
&lt;h2&gt;Copilot&lt;/h2&gt;
&lt;p&gt;I've been using Copilot from GitHub for three months. That is, I pay $10 a month for it. Is it worth it? To be honest, for me - yes. I really like to delegate writing comments, docstrings and other documentation to Copilot. In most cases, it does this well, but if you need something else, something more, then on the second or third try it picks up what you want from it - in what style to write docstrings, in what terms, and from which modules and packages.&lt;/p&gt;
&lt;img alt="Copilot generates docstrings" src="/assets/images/articles/qa/ai_practices_used_for_qa/documenting.jpg" /&gt;
&lt;p&gt;This functionality at last, but not least, for me is worth the time I would have spent writing documentation. But the functionality of copilot is not limited to just generating documentation. Copilot can also generate code, functions, classes. For simplicity, I assume Copilot as an enhanced version of IDE hint mechanism. As far you started to write code, it will spit out the most likely completions of your code to you. This doesn't always work as I expected, but at least you'll have the option to choose both the copilot hint or classic IDE substitution. As for generating code from the description, and even more so from the function name everything getting worse. AI can generate skeletons and some trivial functions, or vary those that you have already written. But if you need some specific logic, then, most probably, you will have to write it by yourself. And here's an important nuance - as a developer tool, Copilot is more of a fifth wheel than a help - it can easily generate incorrect code that you will then have to debug. But as a test automation tool, it’s not bad at all: producing similar tests in essence literally just by pressing 2-3 keys on the keyboard to complete whole test at all. This accelerates the work by an order of magnitude.&lt;/p&gt;
&lt;img alt="Copilot generates code" src="/assets/images/articles/qa/ai_practices_used_for_qa/code_generation.jpg" /&gt;
&lt;p&gt;Do you need to test your webform? Just write one or two tests, and then start writing the name of the test and now you have all the rest written. In total, as in the case of Junior tester and in the case of Copilot, you will need to provide both of them examples, stories and show them how to write tests correctly: to use generators instead of hardcode, and bot of them most probably need to have a ready-made POM (or at least part of it). Yes, for sure, you can try to extract it from the generation, but not everything is as rosy as if you were to supplement it by analogy. On the other hand, Сopilot can explain someone else’s code quite well if you need it. It can fix errors in code and optimize, shorten the code (note that it can do this in unusual and unexpected way and even discard what you need - but, again, you can adjust it). Last what you can do using Copilot is to generate unit tests based on the source code of your software.&lt;/p&gt;
&lt;img alt="Unit tests generation" src="/assets/images/articles/qa/ai_practices_used_for_qa/unit_testing.jpg" /&gt;
&lt;p&gt;And, actually, quite accurately and not bad at all, even with mocking. This is quite impressive, but you still need to keep in mind that there is always a chance that something will not work either the first or the fifth time. Because, I saying it one more time: Copilot, like any other AI, also have a problem with the size of the context, that is, the depth of your calls , code, and its complexity and specific architecture. So, it’s more Junior AI engineer, not a Middle, you still cannot delegate to it the task like: “cover my functionality with 100% tests.” It won't cover. At least without your active participation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="best-practice-and-qa-tasks"&gt;
&lt;h2&gt;Best practice and QA tasks&lt;/h2&gt;
&lt;p&gt;Whether you use Copilot or not, other regular QA tasks can also  be delegated to AI. For example, every day when I write tests, I ask LLM to write me locators or even whole POM objectsusing my template. How it looks like: I provide the AI bot the source code of the page and ask it to generate POM objects for me. This accelerates my work, but at the same time, the result still needs to be revised and iteratively improved. For example, the locators that the bot will quickly produce will be too far from good. So you will need to clarify what and how you want to be shorten and improved. The AI bot is the same Junior guy who needs to learn that them don’t just need to take and copy a huge XPATH from the browser dev tools. You know, cause it will break as far next very first change will be introduced to frontend.&lt;/p&gt;
&lt;img alt="If you don't teach AI, it will generate bad locators" src="/assets/images/articles/qa/ai_practices_used_for_qa/bad_locator.jpg" /&gt;
&lt;p&gt;Well, of course, this applies not only to UI testing, but also to API: you also can pass Swagger’s JSON file to AI and ask it to write test base - cover API endpoints calls in your code and tests for responses and parameters of them. In general, if your team have good software architecture and documentation, you can get ready-made tests on the fly. If necessary, provide extra the requirements and documentation to the model and adjust it to expand your model. How it may look? Pass URL to AI bot, tell it to write tests, then rewrite them in POM style, and here they are ready-made tests. Moreover, you can find that other AI services and tools already exist. That not only allow you to write tests on the fly, but also “poke” your site live with a robot just from your user browser session. It looks impressive and replaces the work of a manual tester who sits behind you under your control. Only difference is here, that it can immediately write down the autotest code. Well, I’m talking about Sider.ai, which is not a cheap, but at least you need to try it.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="growing-the-electronic-middle-tester"&gt;
&lt;h2&gt;Growing the electronic Middle tester&lt;/h2&gt;
&lt;p&gt;And here we got to the most frustrating problem: the lack of AI of your context. Let’s say, no matter how wonderful the AI is, it will not have ability to use for test cookieSSO to obtain information from externally closed pages and system. Also, if you need your own style and code, your framework, you need to provide your own code base and/or documentation, so, you may need to use some embeddings package in model. This is the first problem: most likely your autotests already use yours some test framework and bindings, your POM functions and helpers that the AI does not know about. Second problem, that it would be nice not to sit with the AI and copy HTML/JSON to it, then receive a response, copy it into your code, and then check, and back, and repeat. Why not to delegate it to AI? Just say: “Hey, dude, come back with final result”! Well, I, and, most likely you, want that it’s not a Junior, but such an electronic Middle tester. Is it possible to achieve? The task of grew up a manually driven Junior tester into a semi-automatic Middle still assigned on you. And you must perform. Bot, take a break and review: it’s almost done. Generally speaking, the AI has all the necessary part. It can generate locators, page objects, and tests based on them too. We need to unite, assemble and give AI the opportunity to receive feedback on the nonsense that he wrote, generate and change. So, let's send errors back to it, so that it may fix the code. Do you want also to fix styles and docstrings, cases, issues? Let AI fix it until he gets 100% pass rate of runners and linters.&lt;/p&gt;
&lt;img alt="Test Driven Development as it is" src="/assets/images/articles/qa/ai_practices_used_for_qa/tdd.png" /&gt;
&lt;p&gt;As a prototype, proof-of-concept, I will use my OpenAI wrapper. In order to get something expected and reasonable from the AI, I will use ChatGPT4, and I will also need to use functions that will do all the dirty work: function call to receive page content and function call to run tests. So, that means that I need to use the gpt-4-0613 model.&lt;/p&gt;
&lt;img alt="AI generator scheme" src="/assets/images/articles/qa/ai_practices_used_for_qa/scheme.png" /&gt;
&lt;p&gt;I will use pytest+selenium as a framework cause of simplicity, regularity  and familiarity (and because the mine OpenAI wrapper is also written using Python). My entire testing framework will consist of just one conftest file with a driver fixture, a runner, and by default we will assume that for each unique page we de facto have a fixture that will open the required page for testing. In real life, probably, before starting the test, we would go through authentication and somehow manage the environment.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager


def pytest_runtest_makereport(item, call):
    &amp;quot;&amp;quot;&amp;quot;
    Pytest hook for saving html page on test failure

    :param item: pytest item
    :param call: pytest call
    &amp;quot;&amp;quot;&amp;quot;
    if &amp;quot;driver&amp;quot; in item.fixturenames:
        web_driver = item.funcargs[&amp;quot;driver&amp;quot;]
        if call.when == &amp;quot;call&amp;quot; and call.excinfo is not None:
            with open(f&amp;quot;{item.nodeid.split(&amp;#39;::&amp;#39;)[1]}.html&amp;quot;, &amp;quot;w&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as file:
                file.write(web_driver.page_source)


@pytest.fixture
def driver():
    &amp;quot;&amp;quot;&amp;quot;
    Pytest fixture for selenium webdriver

    :return: webdriver
    &amp;quot;&amp;quot;&amp;quot;
    options = Options()
    options.add_argument(&amp;quot;--headless&amp;quot;)
    options.headless = True
    path = ChromeDriverManager().install()
    _driver = webdriver.Chrome(service=ChromeService(executable_path=path, options=options), options=options)

    yield _driver

    _driver.close()
    _driver.quit()
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But let's leave that out. At least we’re experimenting. We are already, in fact, running tests from the “real”-like environment. At first, let's write system instructions for the bot. We need three things from it: 1) I’ll ask to receive the page code (by calling a certain function), and then generate json for it, which will contain page objects and tests in a certain format. 2) Run a specific test and get the result. If there is an error, fix it. 3) Repeat 2.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;1) You may obtain page code by calling &amp;quot;get_page_code&amp;quot; function. It will return you:
 raw HTML document, what needs to be tested (guarded by ```). And you need to respond with json in following format:
{
&amp;quot;page_objects&amp;quot;: [
&amp;quot;@property\\n
    def calculate_button(self):\\n
        return WebDriverWait(self.driver, 10).until(\\n
            EC.presence_of_element_located((By.XPATH, &amp;#39;//button[.=&amp;#39;&amp;#39;&amp;#39;Calculate&amp;#39;&amp;#39;&amp;#39;]&amp;#39;))\\n
        )&amp;quot;, &amp;lt;...&amp;gt;
],
&amp;quot;tests&amp;quot;: [&amp;quot;def test_division_by_zero(page):\\n
    page.numbers_input.send_keys(1024)\\n
    page.divide_button.click()\\n
    page.calculator_input.send_keys(&amp;#39;0&amp;#39;)\\n
    page/calculate_button.click()\\n
    assert page.error.text() == &amp;#39;Error: divide by zero&amp;#39;&amp;quot;, &amp;lt;...&amp;gt;],
}
This means you need to create page objects for each object on the page using laconic and stable XPATH locators (as short and stables as you can, use only By.XPATH locators, not By.ID, not By.CSS_SELECTOR or By.CLASS name), and then create all possible test cases for them. It might be some filed filling tests (errors, border checks, positive and negative cases), clicking, content changing, etc. Please respect to use &amp;#39;page&amp;#39; fixture for every test, it&amp;#39;s predefined in code and opens page under test before it.
2) Then I may ask you to execute some tests. You can run demanded test via &amp;quot;get_tests_results&amp;quot; function, based on gathered content, you need to respond with json in following format:
results = {
    &amp;quot;passed&amp;quot;: [],
    &amp;quot;failed&amp;quot;: [],
    &amp;quot;error&amp;quot;: [],
    &amp;quot;failure details&amp;quot;: {}
}
where &amp;quot;failure details&amp;quot; - is dict with keys equal to test names (which you generated) and possible failures details. If you got an failures and errors, you need to respond as in 1 with fixed code (page objects and/or tests).
Answer only with JSON in format I mentioned in 1. Never add anything more than that (no explanations, no extra text, only json).
3) In addition to 1 and 2 i may pass you extra info what kind of test data might be used (i.e. for form filling), but in general you need to generate all possible scenarios (valid/invalid/border cases, always add what&amp;#39;s not listed by user, but should be for best quality of testing coverage).
&amp;quot;&amp;quot;&amp;quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If necessary, I, as an user, can enhance tests generation with user context (requirements, styling, test data, demanded cases, coverage, etc.).&lt;/p&gt;
&lt;p&gt;In order to reduce gpt tokens consumption, we’ll get a page (it’s better to do this not with a request, but with the help of selenium, so that possible javascript can be processed on the page), then we’ll remove everything unnecessary and insignificant: just leaving only the body and remove all scripts from it. You can easily expand it as you need, for example, removing repeating elements (sidebars, headers, etc.). To do this for prototype, I wrote the PageRetriever class.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from webdriver_manager.chrome import ChromeDriverManager


class PageRetriever:
    &amp;quot;&amp;quot;&amp;quot;The PageRetriever class is for managing an instance of the PageRetriever.&amp;quot;&amp;quot;&amp;quot;

    def __init__(self, url=&amp;quot;&amp;quot;):
        &amp;quot;&amp;quot;&amp;quot;
        General init.

        :param url: (str) URL of the page.
        &amp;quot;&amp;quot;&amp;quot;
        options = Options()
        options.add_argument(&amp;quot;--headless&amp;quot;)
        options.headless = True
        path = ChromeDriverManager().install()
        self.driver = webdriver.Chrome(service=ChromeService(executable_path=path), options=options)
        self.url = url

    def set_url(self, url):
        &amp;quot;&amp;quot;&amp;quot;
        Set the url.

        :param url: (str) URL of the page.
        &amp;quot;&amp;quot;&amp;quot;
        self.url = url

    def get_page(self, url=None):
        &amp;quot;&amp;quot;&amp;quot;
        Get the page content from the url.

        :param url: (str) URL of the page.
        :return: (str) HTML content of the page.
        &amp;quot;&amp;quot;&amp;quot;
        if url:
            self.set_url(url)
        return self.get_page_content(self.url)

    def get_body(self, url=None):
        &amp;quot;&amp;quot;&amp;quot;
        Get the body content of the page.

        :param url: (str) URL of the page.
        :return: (str) Body content of the page.
        &amp;quot;&amp;quot;&amp;quot;
        if url:
            self.set_url(url)
        return self.extract_body_content(self.get_page())

    def get_body_without_scripts(self, url=None):
        &amp;quot;&amp;quot;&amp;quot;
        Get the body content of the page without &amp;lt;script&amp;gt;...&amp;lt;/script&amp;gt; tags.

        :param url: (str) URL of the page.
        :return: (str) Body content of the page without &amp;lt;script&amp;gt;...&amp;lt;/script&amp;gt; tags.
        &amp;quot;&amp;quot;&amp;quot;
        if url:
            self.set_url(url)
        return self.remove_script_tags(self.get_body())

    def get_page_content(self, url):
        &amp;quot;&amp;quot;&amp;quot;
        Get the page content from the url.

        :param url: (str) URL of the page.
        :return: (str) HTML content of the page.
        &amp;quot;&amp;quot;&amp;quot;
        self.driver.get(url)

        WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, &amp;quot;body&amp;quot;)))

        start_time = time.time()
        while True:
            network_activity = self.driver.execute_script(
                &amp;quot;return window.performance.getEntriesByType(&amp;#39;resource&amp;#39;).filter(item =&amp;gt; &amp;quot;
                &amp;quot;item.initiatorType == &amp;#39;xmlhttprequest&amp;#39; &amp;amp;&amp;amp; item.duration == 0)&amp;quot;
            )
            if not network_activity or time.time() - start_time &amp;gt; 30:
                break

        content = self.driver.page_source
        self.driver.close()
        self.driver.quit()

        return content

    @staticmethod
    def extract_body_content(html_content):
        &amp;quot;&amp;quot;&amp;quot;
        Extract the body content from the html_content.

        :param html_content: (str) HTML content of the page.
        :return: (str) Body content of the page.
        &amp;quot;&amp;quot;&amp;quot;
        soup = BeautifulSoup(html_content, &amp;quot;html.parser&amp;quot;)
        body_content = soup.body

        return str(body_content)

    @staticmethod
    def remove_script_tags(input_content):
        &amp;quot;&amp;quot;&amp;quot;
        Remove all &amp;lt;script&amp;gt;...&amp;lt;/script&amp;gt; tags from the input_content.

        :param input_content: (str) HTML content of the page.
        :return: (str) Body content of the page without &amp;lt;script&amp;gt;...&amp;lt;/script&amp;gt; tags.
        &amp;quot;&amp;quot;&amp;quot;
        pattern_1 = re.compile(r&amp;quot;&amp;lt;script.*?&amp;gt;.*?&amp;lt;/script&amp;gt;&amp;quot;, re.DOTALL)
        pattern_2 = re.compile(r&amp;quot;&amp;lt;path.*?&amp;gt;.*?&amp;lt;/path&amp;gt;&amp;quot;, re.DOTALL)
        output = re.sub(pattern_1, &amp;quot;&amp;quot;, input_content)
        output = re.sub(pattern_2, &amp;quot;&amp;quot;, output)
        return output
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;We also need a runner that will receive data for AI feedback on completed tests. Let's say we use the pytest-json-report plugin to obtain test results data. In the report I will add information about passed and failed tests, for each failed test I will add the error itself (if necessary, you can put a traceback there also), and it would also be a good idea to send back the page code at the time of the failure happened. This will be useful for the AI to see what has changed on the page so to be able to change actual to the the correct expected values. To be honest, in real life, the pages are not so small, and providing a page for every error is too exhaustive. So we will still be limited by the size of the content and the relatively high cost in tokens of such an experiment. But, what is actual truth that AI's work costs are cents, not hundreds of dollars like human being Junior/Middle tester..&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import pytest

from utils.page_retriever import PageRetriever


def run_tests(test_files, add_failed_html=True, add_failure_reasons=True, count_of_htmls=1):
    &amp;quot;&amp;quot;&amp;quot;
    Run tests and return results in JSON format.

    :param test_files: (list) list with test files.
    :param add_failed_html: (bool) boolean to add html report.
    :param add_failure_reasons: (bool) boolean to add failure reasons.
    :param count_of_htmls: (int) count of htmls to add. Doesn&amp;#39;t recommend to use more than 1.

    :return: JSON with results.
    &amp;quot;&amp;quot;&amp;quot;
    pytest.main(
        [
            &amp;quot;-q&amp;quot;,
            &amp;quot;--json-report&amp;quot;,
            &amp;quot;--json-report-file=test_report.json&amp;quot;,
            &amp;quot;-n=4&amp;quot;,
            &amp;quot;-rfEx --tb=none -p no:warnings -p no:logging&amp;quot;,
        ]
        + test_files
    )

    with open(&amp;quot;test_report.json&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as json_file:
        data = json.load(json_file)

    results = {&amp;quot;passed&amp;quot;: [], &amp;quot;failed&amp;quot;: [], &amp;quot;error&amp;quot;: [], &amp;quot;failure details&amp;quot;: {}, &amp;quot;failed_pages&amp;quot;: {}}

    for test in data[&amp;quot;tests&amp;quot;]:
        node_name = test[&amp;quot;nodeid&amp;quot;].split(&amp;quot;::&amp;quot;)[1]
        if test[&amp;quot;outcome&amp;quot;] == &amp;quot;passed&amp;quot;:
            results[&amp;quot;passed&amp;quot;].append(node_name)
        elif test[&amp;quot;outcome&amp;quot;] == &amp;quot;failed&amp;quot; or test[&amp;quot;outcome&amp;quot;] == &amp;quot;error&amp;quot;:
            results[test[&amp;quot;outcome&amp;quot;]].append(node_name)
            if add_failure_reasons:
                results[&amp;quot;failure details&amp;quot;][node_name] = {node_name: test[&amp;quot;call&amp;quot;][&amp;quot;crash&amp;quot;]}
            if add_failed_html:
                if len(results[&amp;quot;failed_pages&amp;quot;]) &amp;lt; count_of_htmls:
                    results[&amp;quot;failed_pages&amp;quot;][node_name] = {node_name: parse_error_page(node_name)}

    json_results = json.dumps(results)

    return json_results


def parse_error_page(node_name):
    &amp;quot;&amp;quot;&amp;quot;
    Parse error page.

    :param node_name: (str) name of the node.

    :return: (str) formatted content of the page.
    &amp;quot;&amp;quot;&amp;quot;
    parser = PageRetriever()
    try:
        file_name = f&amp;quot;{node_name}.html&amp;quot;
        with open(file_name, &amp;quot;r&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as file:
            formatted_content = parser.remove_script_tags(parser.extract_body_content(file))
        remove(file_name)
        return formatted_content
    except io.UnsupportedOperation:
        return &amp;quot;No page available.&amp;quot;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next steps: I add functions and json for ChatGPT, which will call PageRetriever and Runner, respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;doc_engine = PageRetriever()
gpt_functions = [
    {
        &amp;quot;name&amp;quot;: &amp;quot;get_page_code&amp;quot;,
        &amp;quot;description&amp;quot;: &amp;quot;Get page code to generate locators and tests&amp;quot;,
        &amp;quot;parameters&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;object&amp;quot;,
            &amp;quot;properties&amp;quot;: {&amp;quot;url&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;, &amp;quot;description&amp;quot;: &amp;quot;The URL of the page to get the code from&amp;quot;}},
            &amp;quot;required&amp;quot;: [],
        },
    },
    {
        &amp;quot;name&amp;quot;: &amp;quot;get_tests_results&amp;quot;,
        &amp;quot;description&amp;quot;: &amp;quot;Get the results of the tests&amp;quot;,
        &amp;quot;parameters&amp;quot;: {
            &amp;quot;type&amp;quot;: &amp;quot;object&amp;quot;,
            &amp;quot;properties&amp;quot;: {
                &amp;quot;test_files&amp;quot;: {
                    &amp;quot;type&amp;quot;: &amp;quot;array&amp;quot;,
                    &amp;quot;items&amp;quot;: {&amp;quot;type&amp;quot;: &amp;quot;string&amp;quot;},
                    &amp;quot;description&amp;quot;: &amp;quot;The list of test files to run&amp;quot;,
                }
            },
            &amp;quot;required&amp;quot;: [],
        },
    },
]

gpt_functions_dict = {
    &amp;quot;get_page_code&amp;quot;: doc_engine.get_body_without_scripts,
    &amp;quot;get_tests_results&amp;quot;: run_tests,
}
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since we expect the AI to return only tests and POMs elements, and not entire files (this way we also save a little tokens), we need to take this on ourselves and write a class that will recreate the file every time it needed. We will call it ourselves, but we could ask the AI to do this also, or even make a separate variation so that the headers of the files is created for our tests. Here you can further improve it - add logic for updating the file rather than re-creating it, adding tests to existing ones, and so on. But for the experiment, it’s enough for me to simply recreate the entire file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from urllib.parse import urlparse, unquote


class PomTestCaseGenerator:
    &amp;quot;&amp;quot;&amp;quot;Class for generating test files and page objects from json data&amp;quot;&amp;quot;&amp;quot;

    def __init__(self, url=&amp;quot;&amp;quot;):
        &amp;quot;&amp;quot;&amp;quot;
        General init.

        :param url: (str) URL of the page.
        &amp;quot;&amp;quot;&amp;quot;
        self.url = url

    def set_url(self, url):
        &amp;quot;&amp;quot;&amp;quot;
        Set the url.

        :param url: (str) URL of the page.
        &amp;quot;&amp;quot;&amp;quot;
        self.url = url

    def ___create_pom_file(self, file_name, page_objects, url=&amp;quot;&amp;quot;, pom_folder=&amp;quot;pom&amp;quot;):
        &amp;quot;&amp;quot;&amp;quot;
        Create page object model file.

        :param file_name: (str) Name of the file.
        :param page_objects: (list) List of page objects.
        :param url: (str) URL of the page.
        :param pom_folder: (str) Folder for page object model files.
        &amp;quot;&amp;quot;&amp;quot;
        if not url:
            url = self.url
        if not os.path.exists(pom_folder):
            os.makedirs(pom_folder)
        with open(f&amp;quot;{pom_folder}/page_{file_name}.py&amp;quot;, &amp;quot;w&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as pom_file:
            pom_file.write(&amp;quot;from selenium.webdriver.common.by import By\n&amp;quot;)
            pom_file.write(&amp;quot;from selenium.webdriver.support.ui import WebDriverWait\n&amp;quot;)
            pom_file.write(&amp;quot;from selenium.webdriver.support import expected_conditions as EC\n\n\n&amp;quot;)
            pom_file.write(f&amp;#39;class Page{&amp;quot;&amp;quot;.join(word.capitalize() for word in file_name.split(&amp;quot;_&amp;quot;))}:\n&amp;#39;)
            pom_file.write(&amp;quot;    def __init__(self, driver):\n&amp;quot;)
            pom_file.write(f&amp;#39;        self.url = &amp;quot;{url}&amp;quot;\n&amp;#39;)
            pom_file.write(&amp;quot;        self.driver = driver\n\n&amp;quot;)
            for method in page_objects:
                pom_file.write(f&amp;quot;    {method}\n\n&amp;quot;)

    @staticmethod
    def ___create_test_file(file_name, tests, pom_folder=&amp;quot;pom&amp;quot;, tests_folder=&amp;quot;tests&amp;quot;):
        &amp;quot;&amp;quot;&amp;quot;
        Create test file.

        :param file_name: (str) Name of the file.
        :param tests: (list) List of tests.
        :param pom_folder: (str) Folder for page object model files.
        :param tests_folder: (str) Folder for test files.
        &amp;quot;&amp;quot;&amp;quot;
        with open(f&amp;quot;{tests_folder}/test_{file_name}.py&amp;quot;, &amp;quot;w&amp;quot;, encoding=&amp;quot;utf-8&amp;quot;) as test_file:
            test_file.write(&amp;quot;import pytest\n\n&amp;quot;)
            test_file.write(
                f&amp;#39;from {pom_folder}.{os.path.splitext(f&amp;quot;page_{file_name}&amp;quot;)[0]} import Page&amp;#39;
                f&amp;#39;{&amp;quot;&amp;quot;.join(word.capitalize() for word in file_name.split(&amp;quot;_&amp;quot;))}\n\n\n&amp;#39;
            )
            test_file.write(&amp;#39;@pytest.fixture(scope=&amp;quot;function&amp;quot;)\n&amp;#39;)
            test_file.write(&amp;quot;def page(driver):\n&amp;quot;)
            test_file.write(
                f&amp;#39;    page_under_test = Page{&amp;quot;&amp;quot;.join(word.capitalize() for word in file_name.split(&amp;quot;_&amp;quot;))}(driver)\n&amp;#39;
            )
            test_file.write(&amp;quot;    driver.get(page_under_test.url)\n&amp;quot;)
            test_file.write(&amp;quot;    return page_under_test\n\n\n&amp;quot;)
            for test in tests:
                test_file.write(f&amp;quot;{test}\n\n\n&amp;quot;)

    def create_files_from_json(self, json_data, url=&amp;quot;&amp;quot;, pom_folder=&amp;quot;pom&amp;quot;, tests_folder=&amp;quot;tests&amp;quot;):
        &amp;quot;&amp;quot;&amp;quot;
        Create test and page object model files from json data.

        :param json_data: (str) JSON data.
        :param url: (str) URL of the page.
        :param pom_folder: (str) Folder for page object model files.
        :param tests_folder: (str) Folder for test files.
        &amp;quot;&amp;quot;&amp;quot;
        if not url:
            url = self.url
        parsed_url = urlparse(unquote(url))
        file_name = parsed_url.path.strip(&amp;quot;/&amp;quot;).replace(&amp;quot;/&amp;quot;, &amp;quot;_&amp;quot;) or &amp;quot;index&amp;quot;
        self.___create_test_file(file_name, json_data[&amp;quot;tests&amp;quot;], pom_folder=&amp;quot;..pom&amp;quot;, tests_folder=tests_folder)
        self.___create_pom_file(file_name, json_data[&amp;quot;page_objects&amp;quot;], url, pom_folder=pom_folder)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, when we have all the parts, let's just call everything in the right order.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from examples.creds import oai_token, oai_organization
from examples.test_generator.gpt_functions import gpt_functions, gpt_functions_dict
from examples.test_generator.pom_case_generator import PomTestCaseGenerator
from openai_api.src.openai_api import ChatGPT
from openai_api.src.openai_api.logger_config import setup_logger

url_under_test = &amp;quot;https://www.saucedemo.com/&amp;quot;
generator = PomTestCaseGenerator(url=url_under_test)


def setup_gpt():
    &amp;quot;&amp;quot;&amp;quot;Setup GPT bot with appropriate functions and settings&amp;quot;&amp;quot;&amp;quot;
    gpt = ChatGPT(auth_token=oai_token, organization=oai_organization, model=&amp;quot;gpt-4-0613&amp;quot;)
    gpt.logger = setup_logger(&amp;quot;gpt&amp;quot;, &amp;quot;gpt.log&amp;quot;, logging.INFO)
    gpt.system_settings = &amp;quot;&amp;quot;
    gpt.function_dict = gpt_functions_dict
    gpt.function_call = &amp;quot;auto&amp;quot;
    gpt.functions = gpt_functions
    gpt.system_settings = system_instructions
    return gpt


async def main():
    &amp;quot;&amp;quot;&amp;quot;Main function for testing GPT bot&amp;quot;&amp;quot;&amp;quot;
    print(&amp;quot;===Setup GPT bot===&amp;quot;)
    gpt = setup_gpt()
    print(&amp;quot;===Get page code of https://www.saucedemo.com/ and generate POM and tests===&amp;quot;)
    response = await anext(gpt.str_chat(f&amp;quot;Get page code of {url_under_test} and generate POM and tests&amp;quot;))
    print(response)
    response = response.replace(&amp;quot;\n&amp;quot;, &amp;quot;&amp;quot;)
    generator.create_files_from_json(
        json.loads(response), pom_folder=&amp;quot;examples/test_generator/pom&amp;quot;, tests_folder=&amp;quot;examples/test_generator/tests&amp;quot;
    )
    print(&amp;quot;===Get tests results for examples/test_generator/tests/test_index.py==&amp;quot;)
    response = await anext(gpt.str_chat(&amp;quot;Get tests results for examples/test_generator/tests/test_index.py&amp;quot;))
    print(response)
    print(&amp;quot;===If there are failures in code, please fix it by fixing POM and tests===&amp;quot;)
    response = await anext(gpt.str_chat(&amp;quot;If there are failures in code, please fix it by fixing POM and tests&amp;quot;))
    print(response)
    generator.create_files_from_json(
        json.loads(response), pom_folder=&amp;quot;..pom&amp;quot;, tests_folder=&amp;quot;examples/test_generator/tests&amp;quot;
    )


asyncio.run(main())
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Receiving a page, generating and running tests takes one and a half minutes, which is not so bad for the time of one iteration. The results of the “blind” generation look quite good. Yes, it would be possible to write more tests, but overall the AI has written basic checks, and the tests look correct. So, for example, in the first iteration, one out of five passed.&lt;/p&gt;
&lt;img alt="Generated tests. Where is the assert?" src="/assets/images/articles/qa/ai_practices_used_for_qa/generated_test.jpg" /&gt;
&lt;p&gt;Hm… it’s not entirely fair. But in the second iteration, the AI corrected the first test with missing assert, and corrected rest of the the tests based on the test execution results.&lt;/p&gt;
&lt;img alt="Second test iteration: 5/6 test passed" src="/assets/images/articles/qa/ai_practices_used_for_qa/2_iteration.png" /&gt;
&lt;p&gt;Now we have 5 out of 6 tests passing. In just 3 minutes! As you can see, the approach works, and going through page by page you can quickly create working tests for your web application. Taking into account the fact that if you have requirements or documentation, what is still much better and correct way, then by providing the this info to the AI, as well as specifying what scenarios you want to see (negative scenarios? boundary values? flow tests? Injections?) you can achieve very good results in semi-automatic mode, just by passing a set of urls to the script.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="conclusions"&gt;
&lt;h2&gt;Conclusions&lt;/h2&gt;
&lt;p&gt;Now I can’t imagine my life and future work without AI. Using AI in my work increases mine productivity by an order of magnitude. I hope that with the development of AI technology, new approaches, models, services, returns from them will also increase without increasing prices and decreasing the quality. And many things that today require participation and involvement of Seniors testers, SDET, QA managers, will also be delegated to AI. Does this mean that testers are no longer needed? No. Despite all the wonderful descriptive and generative capabilities, AI is just a powerful tool, a machine, if you will, which you also need to know how to use, and if you don’t know how, you can cut off your fingers or even dumb head.&lt;/p&gt;
&lt;/div&gt;
</content><category term="qa, ai"></category><category term="ai"></category><category term="qa"></category><category term="copilot"></category><category term="gpt"></category><category term="testing"></category><category term="automation"></category><category term="python"></category></entry><entry><title>My history of first-person view party-based RPG</title><link href="https://wwakabobik.github.io/2023/09/gaming_first_person_view_party_based_rpg/" rel="alternate"></link><published>2023-09-15T16:14:00+02:00</published><updated>2023-10-23T08:35:50+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-09-15:/2023/09/gaming_first_person_view_party_based_rpg/</id><summary type="html">&lt;p class="first last"&gt;I love first-person view party-based RPGs. Here is a list of games I played and my thoughts about them and future of the genre.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;While gamers are discussing and playing through &lt;a class="reference external" href="https://baldursgate3.game/"&gt;Baldur's Gate 3&lt;/a&gt;, I also want to talk about this one of the oldest and most interesting genres of computer games, about &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Role-playing_video_game"&gt;RPG&lt;/a&gt;. Yes, my favourite RPG is &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate"&gt;Baldur's Gate&lt;/a&gt;, but today is not about it, but about other games. Unlike RPG with isometric third-person view, I want turn to RPGs with first person view, moreover, not to modern first-person-slash-pew-pew-bethesda-style “games”, but to party-based, classic RPGs.  Yes, good old party-based dungeon crawlers.&lt;/p&gt;
&lt;img alt="Every game start with party creation" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/cover.png" /&gt;
&lt;p&gt;Here's how it was... I don't remember at all which game in this genre was my first. I'm inclined to think it was…&lt;/p&gt;
&lt;div class="section" id="ishar-3-the-seven-gates-of-infinity"&gt;
&lt;h2&gt;Ishar 3: The Seven Gates of Infinity&lt;/h2&gt;
&lt;p&gt;This is the third and final part of the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_(series)"&gt;Ishar&lt;/a&gt; series, developed by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Silmarils_(company)"&gt;Silmarils&lt;/a&gt;. In this game, you also control a group of heroes, but this time you embark on a journey across the island of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_2:_Messengers_of_Doom"&gt;Kendoria&lt;/a&gt; to stop the evil wizard &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_3:_The_Seven_Gates_of_Infinity"&gt;Shandar&lt;/a&gt;. &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_3:_The_Seven_Gates_of_Infinity"&gt;Ishar 3&lt;/a&gt; differs from its predecessors with a more open world and greater freedom of action. The game has many different locations, including cities, dungeons, and even other dimensions, as well as a variety of characters with whom you can interact.&lt;/p&gt;
&lt;img alt="Ishar 3: The Seven Gates of Infinity" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/ishar3.jpeg" /&gt;
&lt;p&gt;And all this I, as an 8-9 year old child was not very able to see because of the complexity of the game and the language barrier, but was impressed that among the other games that my father put on the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Intel_80486DX2"&gt;486DX66&lt;/a&gt; computer, you could walk around the streets of the visual city, meet and talk to different characters, and going outside the city to crush monsters, however, already the second or third monster cut in cabbage all my team. But it was worth it! I've been gathering new and new teams from elves, dwarves, orcs and even dragonmen! Warriors and magicians!&lt;/p&gt;
&lt;p&gt;While I was writing this paragraph, I thought that I was probably influenced more by another game. And it was...&lt;/p&gt;
&lt;div class="section" id="realms-of-arkania-2-star-trail"&gt;
&lt;h3&gt;Realms of Arkania 2: Star Trail&lt;/h3&gt;
&lt;p&gt;When I played this game for a first time, role-playing game world opened for me much wider - the adventure began in a cozy tavern, where for the heroes it was necessary to prepare for a full journey - to collect for them patches, sleeping bags, ropes, boilers, and not to forget about armor and weapons, to make a route on the map and go on a journey!&lt;/p&gt;
&lt;img alt="Realms of Arkania 2: Star Trail" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/realms_of_arkania.jpg" /&gt;
&lt;p&gt;Usually my journey ended in the first forest, where the robbers cut off half of my crew, and the other half died of sickness and wounds, from the banal tetanus obtained from the scratch of the rotting nose of the bandit. But still I sometimes get to the dark dungeon of dwarves, where the real adventures and searches for mysteries began.&lt;/p&gt;
&lt;img alt="Realms of Arkania 2: Star Trail tactical combat" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/realms_of_arkania_2.jpeg" /&gt;
&lt;p&gt;The case was also simplified by the translation into Russian. But, like many things with “professional translation”, half of the text still remained in English, which motivated me to reflect on the events, to study the language on my own, to understand why I still need and how to return the stolen &lt;em&gt;salamander&lt;/em&gt; stone &lt;em&gt;Vindaria Leechbronn&lt;/em&gt; in &lt;em&gt;Lowangen&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="other-minor-games-and-tries"&gt;
&lt;h2&gt;Other minor games and tries&lt;/h2&gt;
&lt;p&gt;Most of the games, unfortunately, because of age and unfamiliarity of mechanics and non-native language I can't pass any hard I tried. But apart from &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_3:_The_Seven_Gates_of_Infinity"&gt;Ishar 3&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Realms_of_Arkania"&gt;Realms of Arkania&lt;/a&gt; I had also time to play in &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Stonekeep"&gt;Stonekeep&lt;/a&gt; (what is technically not party RPG).&lt;/p&gt;
&lt;img alt="Stonekeep" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/stonekeep.jpg" /&gt;
&lt;p&gt;Same for &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Anvil_of_Dawn"&gt;Anvil of Dawn&lt;/a&gt;, but some companions may join your party.&lt;/p&gt;
&lt;img alt="Anvil of Dawn" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/anvil_of_dawn.jpg" /&gt;
&lt;p&gt;Colossal &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Lands_of_Lore"&gt;Lands of Lore&lt;/a&gt; (especially 4 CDs for third part), also, with joined companions.&lt;/p&gt;
&lt;img alt="Lands of Lore" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/lands_of_lore.png" /&gt;
&lt;p&gt;And even &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Robinson%27s_Requiem"&gt;Robinson’s Requiem&lt;/a&gt;. The last game, for the sake of justice, in general one of the first in the world “&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Survival_game"&gt;survivals&lt;/a&gt;”. This is absolute hardcore game, where without clues you had to survive on an unknown planet, to cope with wounds, diseases and to deal with completely different flora and fauna.&lt;/p&gt;
&lt;img alt="Robinson’s Requiem" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/robinsons_requiem.jpg" /&gt;
&lt;p&gt;It was then a very bold branch of the RPG genre, and it was only almost two decades later that the genre flourished - from &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Stranded_(2003_video_game)"&gt;Stranded&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/DayZ_(mod)"&gt;Day-Z&lt;/a&gt; to &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Forest_(video_game)"&gt;Forest&lt;/a&gt;, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Subnautica"&gt;Subnautica&lt;/a&gt; and other &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Long_Dark"&gt;Long Dark&lt;/a&gt;-like games.&lt;/p&gt;
&lt;img alt="Stranded" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/stranded.jpg" /&gt;
&lt;div class="section" id="historical-reference"&gt;
&lt;h3&gt;Historical reference&lt;/h3&gt;
&lt;blockquote class="pull-quote"&gt;
Dungeon Master is a first-person RPG game released by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/FTL_Games"&gt;FTL Games&lt;/a&gt; in 1987. This game was revolutionary for many reasons. It introduced real-time instead of step-by-step gameplay, which was an innovation for the genre. Also in the game there was a complex system of magic, requiring players to memorize various runs to create spells.&lt;/blockquote&gt;
&lt;img alt="Dungeon Master" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/dungeon_master.png" /&gt;
&lt;p&gt;Dungeon Master also contributed to the development of the character management system. Instead of managing one character, players managed a group of four, each with its own unique skills and abilities. This added depth and complexity to the gameplay, requiring strategic thinking and planning from players.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Wizardry: Proving Grounds of the Mad Overlord was released in 1981. It was not a full-fledged first-person game, but it already contained elements of dancing-crawler, and it became the basis for many subsequent games in this genre.&lt;/blockquote&gt;
&lt;img alt="Wizardry: Proving Grounds" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/wizardry_1.jpg" /&gt;
&lt;p&gt;So, depending on which criteria we apply, you can consider first-person first-party RPG either &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeon_Master_(video_game)"&gt;Dungeon Master&lt;/a&gt; or &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry:_Proving_Grounds_of_the_Mad_Overlord"&gt;Wizardry - Proving Grounds of the Mad Overlord&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Neither the first game nor the second game I played because of their age, and now they seem morally outdated to me to be playable. But I think I'll need a couple of evenings to get acquainted with the founders of the genre.&lt;/p&gt;
&lt;p&gt;Moreover, running forward, I can say that, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt;, the heir to the very first &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry"&gt;Wizardry&lt;/a&gt;, in my opinion, is one of the best, if not the best game in this genre.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="first-successes"&gt;
&lt;h3&gt;First successes&lt;/h3&gt;
&lt;p&gt;In the '90s, after a series of RPG games that impressed me, which, unfortunately, were still unsuccessful attempts to enter the genre on an equal footing with adult gamers, I fell out of the canvas for a few years and by the end of the 90s plunged into the absolutely dominant &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Real-time_strategy"&gt;RTS&lt;/a&gt; genre.&lt;/p&gt;
&lt;img alt="The Great Encyclopedia of Computer Games" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/encyclopedia.jpeg" /&gt;
&lt;p&gt;But since this is a completely different story, let’s go back to the late 90’s, when reading “&lt;a class="reference external" href="https://knigogid.ru/books/366758-enciklopediya-kompyuternyh-igr-dlya-ibm-pc-tom-1"&gt;The Great Encyclopedia of Computer Games&lt;/a&gt;” I stumbled upon a praiseful article with a detailed description of the game...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="eye-of-the-beholder"&gt;
&lt;h2&gt;Eye of the Beholder&lt;/h2&gt;
&lt;p&gt;Maybe I would've passed the game if it weren't for &lt;a class="reference external" href="https://en.wikipedia.org/wiki/TSR,_Inc."&gt;TSR&lt;/a&gt;, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Forgotten_Realms"&gt;Forgotten Realms&lt;/a&gt;. The game was about the same universe as the books I read from.&lt;/p&gt;
&lt;img alt="Dragon Lance books" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/dragon_lance.jpg" /&gt;
&lt;p&gt;I was reading &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dragonlance"&gt;Dragon Lance&lt;/a&gt;, and I was admired by the amazing adventures, my magic, and the bravery of adventurers. And then the game promised to plunge into the dark underground of this universe. Could I stand it?&lt;/p&gt;
&lt;img alt="Eye of the Beholder" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/eye_of_the_beholder.jpg" /&gt;
&lt;p&gt;Generally speaking, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Eye_of_the_Beholder_(video_game)"&gt;Eye of the Beholder&lt;/a&gt; cannot boast a good plot, especially when compared to &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ishar_(series)"&gt;Ishar&lt;/a&gt; or &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Realms_of_Arkania:_Star_Trail"&gt;Star Trail&lt;/a&gt;. The plot is as simple as a tail: “The evil is underneath the city - you need to go down and deal with it, do not come back until you figure it out”. Actually, the whole story. But since the game was made by developers from &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Westwood_Studios"&gt;Westwood&lt;/a&gt;, the authors of my favorite series of adventure games - &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Legend_of_Kyrandia"&gt;Legends of Kyrandia&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Legends of Kyrandia" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/legends_of_kyrandia2.jpeg" /&gt;
&lt;p&gt;Just like in her wonderful point-and-click adventure, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Westwood_Studios"&gt;Westwood&lt;/a&gt; has been scrupulous about the details - a very beautiful and thoughtful interface, beautiful and oppressive, atmospheric underground, beautiful monsters, and most importantly - a lot of puzzles, often deadly and... the absence of the map, but the absolute need to draw it on paper. After all, each level was a real maze, from which it was difficult to find a way out.Nevertheless, the game fascinated me so much that, drawing the floor after the floor in a notebook in a cage, I went through all three parts, moving the team of travelers from game to game. &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Eye_of_the_Beholder_(video_game)"&gt;Eye of the beholder&lt;/a&gt; was my first passed party RPG from the first person.&lt;/p&gt;
&lt;img alt="Eye of the Beholder" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/eye_of_the_beholder_2.jpg" /&gt;
&lt;p&gt;And,, remains one of the most favorite, putting in the idea of what the genre of smart &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeon_crawl"&gt;dungeon crawler&lt;/a&gt; should look like. With the increasing complexity of puzzles, monsters, as well as the sensation of the strength of the heroes, first overcoming one Beholder’s, and then crossing entire castles with these creatures, in the hope of fighting with the ancient dragon.&lt;/p&gt;
&lt;img alt="Wizards of the Coast" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/woc.png" /&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/TSR,_Inc."&gt;TSR&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Forgotten_Realms"&gt;Forgotten realms&lt;/a&gt;, generally &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeons_%26_Dragons"&gt;D&amp;amp;D&lt;/a&gt; rules greatly expanded my gaming experience, and laid the foundation for integration into the world's hick culture. Russia did not have any &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeons_%26_Dragons"&gt;D&amp;amp;D&lt;/a&gt; accessibility in the 1990s, unlike the USA. No one knew what it was - &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeons_%26_Dragons"&gt;D&amp;amp;D&lt;/a&gt; and what the worlds were. And it was only through books and computer games that I was able to join an important cultural layer, which, of course, I do not regret, but I am proud of.&lt;/p&gt;
&lt;img alt="Books of Robert Salvatore" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/books.jpg" /&gt;
&lt;p&gt;About after passing the third part of the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Eye_of_the_Beholder_(video_game)"&gt;EOB&lt;/a&gt; I started reading books about &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Drizzt_Do%27Urden"&gt;Drizzt Do’Urden&lt;/a&gt; by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/R._A._Salvatore"&gt;Robert Salvatore&lt;/a&gt;. But, unfortunately, worthy games about the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Dark_Elf_Trilogy"&gt;Dark Elf&lt;/a&gt; never came out.&lt;/p&gt;
&lt;p&gt;I tried to play the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Menzoberranzan_(video_game)"&gt;Menzoberranzan&lt;/a&gt;, but it was much worse than the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Eye_of_the_Beholder_(video_game)"&gt;Eye of the Beholder&lt;/a&gt; series.&lt;/p&gt;
&lt;img alt="Menzoberranzan" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/menzoberranzan.jpg" /&gt;
&lt;p&gt;I remember trying to go through &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ravenloft:_Strahd%27s_Possession"&gt;Ravenloft&lt;/a&gt; and I would probably stick in it for a bit...&lt;/p&gt;
&lt;img alt="Ravenloft" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/ravenloft.jpg" /&gt;
&lt;p&gt;But if by that time in 1998 &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate"&gt;Baldur's Gate&lt;/a&gt; was not released, which once again, a second time changed my idea of the genre.&lt;/p&gt;
&lt;img alt="Baldur's Gate" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/baldurs_gate.jpg" /&gt;
&lt;div class="section" id="second-approach"&gt;
&lt;h3&gt;Second approach&lt;/h3&gt;
&lt;p&gt;Honestly, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate"&gt;Baldur's Gate&lt;/a&gt; so turned me around and dragged me into &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Forgotten_Realms"&gt;Forgotten Realms&lt;/a&gt;, forcing me to go through both parts, then both parts of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Icewind_Dale"&gt;Icewind Dale&lt;/a&gt;, that maybe I’t have thought of any other games in this genre if it hadn’t been literature again.&lt;/p&gt;
&lt;img alt="Icewind Dale" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/icewind_dale.jpg" /&gt;
&lt;p&gt;I became very interested to explore further and further what the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate"&gt;Baldur's Gate&lt;/a&gt;, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Waterdeep"&gt;Waterdeep&lt;/a&gt;, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Mithral_Hall"&gt;Mithral Hall&lt;/a&gt;, as well as the magnificent &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Amn_(Forgotten_Realms)"&gt;Amn&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Neverwinter"&gt;Neverwinter&lt;/a&gt; look like. I found at the &amp;quot;Olympic&amp;quot; flea market two worn-out volumes of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Kate_Novak"&gt;Kate Novak&lt;/a&gt;'s &amp;quot;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Curse_of_the_Azure_Bonds"&gt;Curse of Azure Bonds&lt;/a&gt;&amp;quot; and &amp;quot;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Pool_of_Radiance"&gt;Pool of Radiance&lt;/a&gt;&amp;quot; by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/James_M._Ward"&gt;James Ward&lt;/a&gt;'s &amp;quot;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Pool_of_Darkness"&gt;Pool of Darkness&lt;/a&gt;&amp;quot; by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Jane_Cooper_Hong"&gt;Jane Cooper Gong&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Pool of Radiance" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/pool_of_radiance.gif" /&gt;
&lt;p&gt;Of course, I could not but want to turn to the origins of the genre: to play in the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Pool_of_Radiance"&gt;Pool of Radiance&lt;/a&gt;, but here played again the factor of moral obsolescence of the game (especially in the background of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate"&gt;BG&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Icewind_Dale"&gt;ID&lt;/a&gt;), that I never exceeded myself. It was replaced by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt; and &lt;a class="reference internal" href="#wizards-warriors"&gt;Wizards &amp;amp; Warriors&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="wizardry-8"&gt;
&lt;h2&gt;Wizardry 8&lt;/h2&gt;
&lt;p&gt;This is the latest game in the classic &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry"&gt;Wizardry&lt;/a&gt; series, and in all respects it is the culmination of everything that makes this series so remarkable. The game was released in 2001 by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Sir-Tech"&gt;Sir-Tech&lt;/a&gt;, and it represents an epic adventure in the RPG genre.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
The game takes place in the world of Dominus, where the cosmic god of chaos, Dark Savant, is trying to find the secret of Ascension Peak. Your group of adventurers, known as &amp;quot;Dark Savant's party&amp;quot;, travel through the universe in search of three powerful artifacts. Your mission is to find these artifacts and use them to access the Ascension Peak and contact the cosmic gods.&lt;/blockquote&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt; offers you a huge open world to explore, hundreds of tasks and a deep, sophisticated battle system. You can create your own group of different races and classes, each of which has its own unique abilities and skills.&lt;/p&gt;
&lt;img alt="Wizardry 8" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/wizardry_8.jpeg" /&gt;
&lt;p&gt;&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt; became like an &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Eye_of_the_Beholder_(video_game)"&gt;EOB&lt;/a&gt; for me on highlights, I passed it with the same pleasure as the masterpiece from &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Westwood_Studios"&gt;Westwood&lt;/a&gt;. Despite the fact that the era of party RPGs from the first person began to go back to the past, the game brought for me an immersion in the present 3D, with very juicy picture and sounds, with a consistent plot and verified puzzles and difficult solutions.&lt;/p&gt;
&lt;img alt="Wizardry 8" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/wizardry_8_1.jpeg" /&gt;
&lt;p&gt;Yes, once again I would like to point out that for me &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt; is the masterpiece of the genre, the quintessence of how to make games correctly, guide the player and create difficulties for him, without descending to grind and self-repetition. But, to be honest, literally a year before that, the game came out with more interesting mechanics and more thought-out physics, namely...&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="wizards-warriors"&gt;
&lt;h2&gt;Wizards &amp;amp; Warriors&lt;/h2&gt;
&lt;p&gt;It was released in 2000 by &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Heuristic_Park"&gt;Heuristic Park&lt;/a&gt;. The game combines elements of classical and modern gameplay, offering a unique experience for fans of the genre.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Wizards and Warriors is set in the fantasy world of Daventry. The kingdom is in danger, as the evil wizard Malkil has kidnapped the princess and cast a spell of darkness over the land.
You play as a powerful hero named Kuros, who embarks on a dangerous journey to save the princess and restore peace in the kingdom. Your mission is to fight evil forces, solve puzzles and explore various underground areas.&lt;/blockquote&gt;
&lt;p&gt;&lt;a class="reference internal" href="#wizards-warriors"&gt;Wizards &amp;amp; Warriors&lt;/a&gt; offers you a vast world to explore, with many different locations, from castles and caves to forests and mountains. The game also has a unique fighting system that allows you to use different strategies and tactics.&lt;/p&gt;
&lt;img alt="Wizards &amp;amp; Warriors" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/wizards_and_warriors.jpeg" /&gt;
&lt;p&gt;The fighting at &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizards_%26_Warriors_(video_game)"&gt;W&amp;amp;W&lt;/a&gt; felt fresh, more dynamic and more diverse. Rather, the battles were more interesting from a tactical point of view, the puzzles felt more personally. Yeah, but, in the story, the atmosphere &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry_8"&gt;Wizardry 8&lt;/a&gt; was better anyway. It was fairly easy for me to compare the games, as I played both games at the same time, approximately in late 2001 - early 2002, after &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Baldur%27s_Gate_II:_Shadows_of_Amn"&gt;Baldur's Gate 2&lt;/a&gt;. Today I remain in my opinion that these are some of the latest, and the best RPG in the genre.&lt;/p&gt;
&lt;div class="section" id="missed-milestone"&gt;
&lt;h3&gt;Missed milestone&lt;/h3&gt;
&lt;p&gt;Fans of the genre are probably expecting an answer from me to the question why I missed two key universes for the genre, namely &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Might_and_Magic"&gt;Might &amp;amp; Magic&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls"&gt;The Elder Scrolls&lt;/a&gt;. There's a simple answer: I don't like these universes. Yeah, now I'm ready to take the hool and hear at my address that I have &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeons_%26_Dragons"&gt;D&amp;amp;D&lt;/a&gt; of the brain, but yet to these franchises I have a completely different attitude.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="might-and-magic"&gt;
&lt;h2&gt;Might and Magic&lt;/h2&gt;
&lt;p&gt;Yes, the series passed me at its peak, just like &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Ultima_(series)"&gt;Ultima&lt;/a&gt;. The base of the series was released before 1994, and at the time of familiarization with the genre had time to noticeably obsolete in moral and graphical terms. This does not mean that I judge games by graphics, but when there is a choice a child is more interested in new things, or things in which he lives in his imagination and surroundings. The subsequent parts were released in 1998-2000, when the world was ruled by isometric RPGs. And in its niche, even the 2000 &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Might_and_Magic_VIII:_Day_of_the_Destroyer"&gt;Day of the Destroyer&lt;/a&gt;, part 8 of the series looked both gameplay-friendly, and visually not as powerful as &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Wizardry"&gt;Wizardry&lt;/a&gt; or &lt;a class="reference internal" href="#wizards-warriors"&gt;Wizards &amp;amp; Warriors&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Might and Magic 7: For Blood and Honor" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/might_and_magic_7.jpg" /&gt;
&lt;p&gt;Despite this, in high school, in 2002-2003, I played the seventh and eighth parts, and I couldn't help playing because I loved &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Heroes_of_Might_and_Magic"&gt;Heroes of Might and Magic&lt;/a&gt; crazy. But, here we have to make a reminder - none of the campaigns I passed and didn't want to happen. I played in separate scenarios and created new scenarios myself, we exchanged scenarios with a classmate, made our company - it was interesting. I specially finished the book &amp;quot;Heroes of Might and Magic&amp;quot; by &lt;a class="reference external" href="https://www.goodreads.com/author/show/135384.Anna_Gurova"&gt;Anna Gurova&lt;/a&gt;, read it in a couple of evenings, but also did not penetrate. And yet, I was interested in listening to my classmate's stories, as if I was watching an exciting stream on &lt;em&gt;Youtube&lt;/em&gt; or &lt;em&gt;Twitch&lt;/em&gt;.&lt;/p&gt;
&lt;img alt="Heroes of Might and Magic inspired book by Anna Gurova." src="/assets/images/articles/gaming/first_person_view_party_based_rpg/heroes_of_might_and_magic.jpeg" /&gt;
&lt;p&gt;In general, the plot of the series did not fascinate me at all, although I am interested in it with a full universe, with pleasure watched and waited for reviews of &lt;a class="reference external" href="https://www.youtube.com/&amp;#64;Krop"&gt;Alexander Krop&lt;/a&gt;. For me, as you understand, the plot component, the proximity of the world is very important for the motivation to go through games and read books. And here she, unfortunately, was and remains great. Not mine, I'm sorry.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="the-elder-scrolls"&gt;
&lt;h2&gt;The Elder Scrolls&lt;/h2&gt;
&lt;p&gt;I met this series when &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls_II:_Daggerfall"&gt;Daggerfall&lt;/a&gt; was released in 1996. De-facto &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls"&gt;The Elder Scrolls&lt;/a&gt; is not a representative of the genre “party rpg” to be present on this list. Nevertheless, of course, the mechanics are very close to them. In addition, the game at the time of release, that is, at the moment of the fingerprints of the pirates, was terribly delayed.&lt;/p&gt;
&lt;img alt="The Elder Scrolls II: Daggerfall" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/daggerfall.jpeg" /&gt;
&lt;p&gt;Given the fairly high entry threshold, the breachability of the game, as well as the deliberately inflated game world, the lack of a clear narrative, as a consequence caused my rejection. For me, the game felt like a broken defect, empty and unnatural. However, all the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Bethesda_Softworks"&gt;Bethesda&lt;/a&gt;'s games in this series remained for me: huge worlds in which I do not believe, yes, the possibility of “living in the game”, but for me this game is not played. It can be lived, for some reason to walk and beat out objects and read kilometers of in-game text (&amp;quot;books&amp;quot;), which does not relate to the plot and the life of the player.&lt;/p&gt;
&lt;img alt="The Elder Scrolls II: Daggerfall fiction books" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/daggerfall_books.jpg" /&gt;
&lt;p&gt;My criticism also focuses on &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls_III:_Morrowind"&gt;Morrowind&lt;/a&gt;, and subsequent &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls_IV:_Oblivion"&gt;Oblivion&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/The_Elder_Scrolls_V:_Skyrim"&gt;Skyrim&lt;/a&gt;. I suppose somebody might like this approach when a person enters the body of a &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dragonborn_(The_Elder_Scrolls)"&gt;Dovahkiin&lt;/a&gt; and begins to live in hoops, to create their own damn universes, but no, no, and again not. For me, RPG is first and foremost a group adventure - involvement in the world, the characters, the canve of the story, and not just having a player in it.&lt;/p&gt;
&lt;div class="section" id="our-time"&gt;
&lt;h3&gt;Our Time&lt;/h3&gt;
&lt;p&gt;Time doesn't spare anyone. And the years that followed were not productive for me in terms of going through RPG games. Initially, this was due to the fact that &lt;a class="reference external" href="https://en.wikipedia.org/wiki/First-person_shooter"&gt;FPS&lt;/a&gt; took over the industry, replaced by numerous open-world actions and survivors. In such a world, hard-to-do with such relicts, which must be dealt with, apart from &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Real-time_strategy"&gt;RTS&lt;/a&gt; and RPG have gone to the past, leaving only room for enthusiasts and small &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Indie_game"&gt;indie&lt;/a&gt; projects. I regret to miss &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Pillars_of_Eternity"&gt;Pillars of Eternity&lt;/a&gt; and the &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Divinity_(video_game_series)"&gt;Divinity&lt;/a&gt; series in the genre of isometric RPGs, supported only by one powerful and radiant &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Larian_Studios"&gt;Larian Studios&lt;/a&gt;, and the games to think transformed into large-scale &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Total_War_(video_game_series)"&gt;Total War&lt;/a&gt; and &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Crusader_Kings"&gt;Crusaders Kings&lt;/a&gt;. But, in general, since the beginning of zero in the genre of party RPF nothing remarkable has come out. Dungeon crawler has been transformed into simplified &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Indie_game"&gt;indie&lt;/a&gt; mechanics, for example, this is very noticeable in the remarkable &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Darkest_Dungeon"&gt;Darkest Dungeon&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Darkest Dungeon" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/darkest_dungeon.jpeg" /&gt;
&lt;p&gt;It can be said that they are some kind of evolutionary continuation of the genre. They offer players to explore the underground, fight monsters and control a team of heroes, but do so in a more stylized and simplified form. Rather than focusing on sophisticated mechanics and strategy, these games often focus on atmosphere, art and storytelling. Or they're turning things over, like &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Iratus:_Lord_of_the_Dead"&gt;Iratus&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Iratus" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/iratus.jpeg" /&gt;
&lt;p&gt;Nevertheless, it was a discovery for me that real diamonds can be found in the midst of emptiness. During this summer vacation, in the mid-day sunshine of the ultraviolet light, I was going under the air conditioner and turning on the laptop with the game. For the holidays I chose a game that was recommended to me by a great immigrant, skimmer, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Dungeons_%26_Dragons"&gt;D&amp;amp;D&lt;/a&gt; lover and dungeon crawler...&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="legends-of-grimrock-2"&gt;
&lt;h2&gt;Legends of Grimrock 2&lt;/h2&gt;
&lt;p&gt;I missed it at time when it was released. And I don't know anything about the first part of the game, but the second one struck my heart.&lt;/p&gt;
&lt;img alt="Legends of Grimrock 2" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/legends_of_grimrock.jpg" /&gt;
&lt;p&gt;It's the same feeling of mysteries and mysteries, fermenting labyrinths and avoiding monsters, only with a face on &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Unity_(game_engine)"&gt;Unity&lt;/a&gt;. So familiar, native and warm that directly takes for the soul - is it not the coast of swords, where the heroes go? Yes, even in the menu there is a setting to disable the drawing of the card - and draw it, as in childhood, in a notebook in a cell. The sensation of research, the growth of characters, the complexity of puzzles and the increase of pleasure in their resolution - as bright as in childhood. In general, &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Legend_of_Grimrock_2"&gt;Legends of Grimrock&lt;/a&gt;, in addition to a few battles - the game is not so much about pumping and battle, but about solving puzzles - with plates, traps, mazes, teleports, and enemies - each type of enemy makes sense not to meet face to face, but also to find its own key, ranging from the composition of the group of adventurers, weapons to behavior in battle.&lt;/p&gt;
&lt;img alt="Legends of Grimrock 2" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/legends_of_grimrock_2.jpeg" /&gt;
&lt;p&gt;In the process, I remembered most of the puzzles with food plates, on which the spider had to be driven, or the puzzle where it was necessary to accomplish the “path of faith” along the magical bridge that arises under my feet, and quite painful scripted moments, when on the cemetery out of the graves horde of zombies, with which you have to survive somehow. And of course, a touching and controversial (not)real ending, which is not very clear what exactly to consider true. But there's no spoilers. If you love old-school RPG - then you obviously should not miss this diamond.&lt;/p&gt;
&lt;img alt="Legends of Grimrock 2" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/legends_of_grimrock_3.jpg" /&gt;
&lt;p&gt;While I was writing this article, I decided to go for a little bit of what else I could miss in the genre, and unfortunately, I was able only to draw attention to &lt;cite&gt;Operencia - The Stolen Sun&lt;/cite&gt;, and partly &lt;cite&gt;Vaporum - Lockdown&lt;/cite&gt; (which is also not quite a party game).&lt;/p&gt;
&lt;img alt="Operencia: The Stolen Sun" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/operencia.jpeg" /&gt;
&lt;p&gt;I don’t stick to the concept of “not playing, but criticizing”, so, I can only hope that if there is inspiration and request, then you can and should get acquainted with the games, what I’m going to do when there is free time.&lt;/p&gt;
&lt;img alt="Vaporum: Lockdown" src="/assets/images/articles/gaming/first_person_view_party_based_rpg/vaporum.jpeg" /&gt;
&lt;p&gt;On the other hand, a very small number of games of the genre of party RPG from the first person, maybe well - time passes, the world is changing along with technologies and requests, and if you want something like that, that is, the old, still unopened classic. And rare diamonds, like the creations of &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Larian_Studios"&gt;Larian&lt;/a&gt; or &lt;a class="reference external" href="https://en.wikipedia.org/wiki/Almost_Human_(video_game_developer)"&gt;Almost Human Games&lt;/a&gt; only shine brighter in the darkness of dark underground...&lt;/p&gt;
&lt;/div&gt;
</content><category term="gaming"></category><category term="gaming"></category><category term="rpg"></category></entry><entry><title>Making AI chatbot to hear and speak</title><link href="https://wwakabobik.github.io/2023/09/ai_learning_to_hear_and_speak/" rel="alternate"></link><published>2023-09-07T11:08:00+02:00</published><updated>2023-10-23T08:35:49+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-09-07:/2023/09/ai_learning_to_hear_and_speak/</id><summary type="html">&lt;p class="first last"&gt;Learning to interact with chatbots in a natural way. How to make a bot speak and listen using Python&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I really like the concept when you can expand the possibilities of perception for artificial intelligence. Today, the chat format is the most understandable and popular for interacting with AI. Of course, communication only through chat warms my introverted soul, brought up on &lt;a class="reference external" href="https://en.wikipedia.org/wiki/FidoNet"&gt;BBS&lt;/a&gt; and stories about &lt;a class="reference external" href="http://www.bofharchive.com/"&gt;BOFH&lt;/a&gt;. But, nevertheless, why not make communication with bots more human, teach them to listen, hear and speak? Everything that will be discussed further in the article is not some kind of unique killer-feature, and has been used in many services that provide access to artificial intelligence, for example, in &lt;a class="reference external" href="https://ablt.ai/"&gt;aBLT.ai&lt;/a&gt; chats. In this article, I want to talk about a Python solution available to anyone.&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/Ph7EQSZPmGc?si=2AgO98dUN2ihiVW-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen&gt;&lt;/iframe&gt;&lt;div class="section" id="transcriptions"&gt;
&lt;h2&gt;Transcriptions&lt;/h2&gt;
&lt;div class="section" id="openai-audio-transcribe"&gt;
&lt;h3&gt;openai.Audio.transcribe&lt;/h3&gt;
&lt;p&gt;You are most likely using ChatGPT as your main LLM engine. If you turn to its &lt;a class="reference external" href="https://platform.openai.com/docs/introduction"&gt;API&lt;/a&gt;, you can find a special &lt;strong&gt;whisper-1&lt;/strong&gt; model, which is also responsible for text transcription. All you need to do to transcribe your voice into text is call the &lt;strong&gt;openai.Audio.atranscribe method&lt;/strong&gt;. Here and below, I will use asynchronous methods where possible. This is more convenient for implementing parallel execution and running.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;openai&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Wrapper for the transcribe function. Returns only the content of the message.&lt;/span&gt;

&lt;span class="sd"&gt;    :param file: Path with filename to transcript.&lt;/span&gt;
&lt;span class="sd"&gt;    :param prompt: Previous prompt. Default is None.&lt;/span&gt;
&lt;span class="sd"&gt;    :param language: Language on which audio is. Default is &amp;#39;en&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;    :param response_format: default response format, by default is &amp;#39;text&amp;#39;.&lt;/span&gt;
&lt;span class="sd"&gt;                           Possible values are: json, text, srt, verbose_json, or vtt.&lt;/span&gt;


&lt;span class="sd"&gt;    :return: transcription (text, json, srt, verbose_json or vtt)&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;kwargs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;prompt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;prompt&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;openai&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;atranscribe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;whisper-1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;response_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;temperature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To call this function, we just pass a file to it.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# this method is for prompting LLM using pure string&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Using a pre-made file is fine, but for the sake of completeness: is it worth assuming that you probably want to record your voice on the fly?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recording-audio-sounddevice"&gt;
&lt;h3&gt;Recording audio: sounddevice&lt;/h3&gt;
&lt;p&gt;The easiest way is to use &lt;strong&gt;sounddevice&lt;/strong&gt;. Since &lt;strong&gt;sounddevice&lt;/strong&gt; records a file in &lt;strong&gt;wav&lt;/strong&gt; format, it is reasonable to convert it to &lt;strong&gt;mp3&lt;/strong&gt; for transmission over the Internet, for this you can use, for example, &lt;strong&gt;pydab&lt;/strong&gt;. As a result, the code will look something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sounddevice&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sd&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;soundfile&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sf&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;record_and_convert_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Records audio for a specified duration and converts it to MP3 format.&lt;/span&gt;

&lt;span class="sd"&gt;This function records audio for a given duration (in seconds) with a specified frequency sample.&lt;/span&gt;
&lt;span class="sd"&gt;The audio is then saved as a temporary .wav file, converted to .mp3 format, and the .wav file is deleted.&lt;/span&gt;
&lt;span class="sd"&gt;The function returns the path to the .mp3 file.&lt;/span&gt;

&lt;span class="sd"&gt;:param duration: The duration of the audio recording in seconds. Default is 5 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;:param frequency_sample: The frequency sample rate of the audio recording. Default is 16000 Hz.&lt;/span&gt;

&lt;span class="sd"&gt;:return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning for &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;s...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;recording&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;duration&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;samplerate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;sd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# Wait until recording is finished&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Recording complete!&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;wave_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.wav&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;sf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frequency_sample&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Temp audiofile saved: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_wav&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;wave_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;mp3_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp3_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Audio converted to MP3 and stored into &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;mp3_file&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mp3_file&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The resulting file can already be fed to the model. But the method looks very clumsy, because the recording continues for a fixed time, no matter how long you speak - less than the set interval and you have to wait for the end of the recording; or more, which will lead to the phrase being cut off. Usually the smartest solution is to implement push-to-talk. While the user presses the button, the recording is in progress. This is how instant messengers and many online chats work.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="recording-audio-audiorecorder"&gt;
&lt;h3&gt;Recording audio: AudioRecorder&lt;/h3&gt;
&lt;p&gt;But I still don't think it's smart enough, because it doesn't fit with the concept of AI having ears. As a console user, it would be more convenient for me to make an implementation without any buttons and keyboard interactions, and always it's better to assign this task to the code. That is: listen constantly, and if speech is noticed in the noise, then recognize it. Well, almost like how Google Assistant, Siri, and smart speakers work in your home. If you don't need to respond to any sound, you can always filter your catch phrase to be recognized first (at the start of the recording).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="n"&gt;pattern&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;r&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;hellos*,?s*bunny&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IGNORECASE&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;prompt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sub&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flags&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;IGNORECASE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;lstrip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Well, for this task you can use for example my &lt;strong&gt;AudioRecorder&lt;/strong&gt; based on &lt;strong&gt;pyaudio&lt;/strong&gt;. It will listen to the microphone and detect noise (speech) against the background of silence using the &lt;strong&gt;RMS&lt;/strong&gt; (Root Mean Square) method. Full implementation below.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;math&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;struct&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;wave&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pyaudio&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    The AudioRecorder class is for managing an instance of the audio recording and conversion process.&lt;/span&gt;

&lt;span class="sd"&gt;    Parameters:&lt;/span&gt;
&lt;span class="sd"&gt;    pyaudio_obj (PyAudio): Instance of PyAudio. Default is pyaudio.PyAudio().&lt;/span&gt;
&lt;span class="sd"&gt;    threshold (int): The RMS threshold for starting the recording. Default is 15.&lt;/span&gt;
&lt;span class="sd"&gt;    channels (int): The number of channels in the audio stream. Default is 1.&lt;/span&gt;
&lt;span class="sd"&gt;    chunk (int): The number of frames per buffer. Default is 1024.&lt;/span&gt;
&lt;span class="sd"&gt;    f_format (int): The format of the audio stream. Default is pyaudio.paInt16.&lt;/span&gt;
&lt;span class="sd"&gt;    rate (int): The sample rate of the audio stream. Default is 16000 Hz.&lt;/span&gt;
&lt;span class="sd"&gt;    sample_width (int): The sample width (in bytes) of the audio stream. Default is 2.&lt;/span&gt;
&lt;span class="sd"&gt;    timeout_length (int): The length of the timeout for the recording (in seconds). Default is 2 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;    temp_dir (str): The directory for storing the temporary .wav and .mp3 files. Default is the system&amp;#39;s temporary dir.&lt;/span&gt;
&lt;span class="sd"&gt;    normalize (float): The normalization factor for the audio samples. Default is 1.0 / 32768.0.&lt;/span&gt;
&lt;span class="sd"&gt;    pa_input (bool): Specifies whether the stream is an input stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;    pa_output (bool): Specifies whether the stream is an output stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;pyaudio_obj&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;PyAudio&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;chunk&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1024&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;paInt16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;16000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;sample_width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;timeout_length&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt;
        &lt;span class="n"&gt;normalize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;32768.0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
        &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        General init.&lt;/span&gt;

&lt;span class="sd"&gt;        This method initializes an instance of the AudioRecorder class with the specified parameters.&lt;/span&gt;
&lt;span class="sd"&gt;        The default values are used for any parameters that are not provided.&lt;/span&gt;

&lt;span class="sd"&gt;        :param pyaudio_obj: Instance of PyAudio. Default is pyaudio.PyAudio().&lt;/span&gt;
&lt;span class="sd"&gt;        :param threshold: The RMS threshold for starting the recording. Default is 15.&lt;/span&gt;
&lt;span class="sd"&gt;        :param channels: The number of channels in the audio stream. Default is 1.&lt;/span&gt;
&lt;span class="sd"&gt;        :param chunk: The number of frames per buffer. Default is 1024.&lt;/span&gt;
&lt;span class="sd"&gt;        :param f_format: The format of the audio stream. Default is pyaudio.paInt16.&lt;/span&gt;
&lt;span class="sd"&gt;        :param rate: The sample rate of the audio stream. Default is 16000 Hz.&lt;/span&gt;
&lt;span class="sd"&gt;        :param sample_width: The sample width (in bytes) of the audio stream. Default is 2.&lt;/span&gt;
&lt;span class="sd"&gt;        :param timeout_length: The length of the timeout for the recording (in seconds). Default is 2 seconds.&lt;/span&gt;
&lt;span class="sd"&gt;        :param temp_dir: The directory for storing the temporary .wav and .mp3 files. Default is temp dir.&lt;/span&gt;
&lt;span class="sd"&gt;        :param normalize: The normalization factor for the audio samples. Default is 1.0 / 32768.0.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_input: Specifies whether the stream is an input stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_output: Specifies whether the stream is an output stream. Default is True.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyaudio_obj&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;chunk&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f_format&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___sample_width&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample_width&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;timeout_length&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;temp_dir&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___normalize&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;normalize&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pa_input&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pa_output&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;init_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;init_stream&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Initializes an audio stream with the specified parameters.&lt;/span&gt;

&lt;span class="sd"&gt;        This function uses PyAudio to open an audio stream with the given format, channels, rate, input, output,&lt;/span&gt;
&lt;span class="sd"&gt;        and frames per buffer.&lt;/span&gt;

&lt;span class="sd"&gt;        :param f_format: The format of the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param channels: The number of channels in the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param rate: The sample rate of the audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_input: Specifies whether the stream is an input stream. A true value indicates an input stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param pa_output: Specifies whether the stream is an output stream. A true value indicates an output stream.&lt;/span&gt;
&lt;span class="sd"&gt;        :param frames_per_buffer: The number of frames per buffer.&lt;/span&gt;
&lt;span class="sd"&gt;        :type frames_per_buffer: int&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The initialized audio stream.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
            &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;channels&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;rate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="nb"&gt;input&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pa_input&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;pa_output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;frames_per_buffer&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;record&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Starts recording audio when noise is detected.&lt;/span&gt;

&lt;span class="sd"&gt;        This function starts recording audio when noise above a certain threshold is detected.&lt;/span&gt;
&lt;span class="sd"&gt;        The recording continues for a specified timeout length.&lt;/span&gt;
&lt;span class="sd"&gt;        The recorded audio is then saved as a .wav file, converted to .mp3 format, and the .wav file is deleted.&lt;/span&gt;
&lt;span class="sd"&gt;        The function returns the path to the .mp3 file.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Noise detected, recording beginning&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;rec&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt;

        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="n"&gt;end&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;end&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___timeout_length&lt;/span&gt;

            &lt;span class="n"&gt;current&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;b&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rec&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;convert_to_mp3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Saves the recorded audio to a .wav file.&lt;/span&gt;

&lt;span class="sd"&gt;        This function saves the recorded audio to a .wav file with a unique filename.&lt;/span&gt;
&lt;span class="sd"&gt;        The .wav file is saved in the specified temporary directory.&lt;/span&gt;

&lt;span class="sd"&gt;        :param recording: The recorded audio data.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .wav file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.wav&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;wave_form&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;wave&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;wb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setnchannels&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___channels&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setsampwidth&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pyaudio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_sample_size&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___format&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setframerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___rate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writeframes&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;recording&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;wave_form&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;convert_to_mp3&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Converts a .wav file to .mp3 format.&lt;/span&gt;

&lt;span class="sd"&gt;        This function converts a .wav file to .mp3 format. The .wav file is deleted after the conversion.&lt;/span&gt;
&lt;span class="sd"&gt;        The .mp3 file is saved with a unique filename in the specified temporary directory.&lt;/span&gt;

&lt;span class="sd"&gt;        :param filename: The path to the .wav file to be converted.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_wav&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;mp3_file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___temp_dir&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mp3_file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;mp3_file_path&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Starts listening for audio.&lt;/span&gt;

&lt;span class="sd"&gt;        This function continuously listens for audio and starts recording when the&lt;/span&gt;
&lt;span class="sd"&gt;        RMS value of the audio exceeds a certain threshold.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The path to the saved .mp3 file if recording was triggered.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;mic_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stream&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___chunk&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;rms_val&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mic_input&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;rms_val&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___threshold&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;record&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;rms&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        Calculates the Root Mean Square (RMS) value of the audio frame.&lt;/span&gt;

&lt;span class="sd"&gt;        This function calculates the RMS value of the audio frame, which is a measure of the power in the audio signal.&lt;/span&gt;

&lt;span class="sd"&gt;        :param frame: The audio frame for which to calculate the RMS value.&lt;/span&gt;

&lt;span class="sd"&gt;        :return: The RMS value of the audio frame.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="n"&gt;count&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___sample_width&lt;/span&gt;
        &lt;span class="n"&gt;f_format&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s2"&gt;h&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;
        &lt;span class="n"&gt;shorts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;struct&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;unpack&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f_format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;shorts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;normal_sample&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___normalize&lt;/span&gt;
            &lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;normal_sample&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;normal_sample&lt;/span&gt;
        &lt;span class="n"&gt;rms&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sum_squares&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;rms&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;1000&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You may need to experiment with the &lt;em&gt;threshold&lt;/em&gt;, &lt;em&gt;timeout&lt;/em&gt;, &lt;em&gt;channels&lt;/em&gt;, &lt;em&gt;sample_length&lt;/em&gt;, &lt;em&gt;chunk&lt;/em&gt;, and &lt;em&gt;rate&lt;/em&gt; parameters depending on your microphone. And finally, the code to get use as for &amp;quot;ears&amp;quot; of bot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;

&lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="speech-recognition"&gt;
&lt;h3&gt;speech_recognition&lt;/h3&gt;
&lt;p&gt;Using &lt;strong&gt;OpenAI&lt;/strong&gt;'s ready-made methods is fine, but the tokens are not free, and you might want to use an alternative approach. Or this method does not suit you at all, because you use, for example, &lt;strong&gt;llama2&lt;/strong&gt; or &lt;strong&gt;Bard&lt;/strong&gt; instead of &lt;strong&gt;ChatGPT&lt;/strong&gt;. Then an alternative solution may be to use the &lt;strong&gt;speech_recognition&lt;/strong&gt; library.
I use &lt;em&gt;google&lt;/em&gt; recognition, but you can use other engines if you want, like &lt;em&gt;wit&lt;/em&gt;, &lt;em&gt;azure&lt;/em&gt;, &lt;em&gt;sphinx&lt;/em&gt;. The library has everything we need so that we can recognize both an audio file and record directly using the &lt;strong&gt;Microphone()&lt;/strong&gt; class. Just like my &lt;strong&gt;AudioRecorder&lt;/strong&gt;, it's convenient to use voice activation. The only thing you need to specify is the language of the audio file. Yes, this is not as flexible and convenient as in the method from OpenAI, where you can omit the language parameter and hope that the system itself will select the correct language, but I personally would recommend to specify the language you speaking in order to avoid errors. An example method might look like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;speech_recognition&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;sr&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    This is wrapper class for Google Transcriptor which uses microphone to get audio sample.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-EN&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;        General init.&lt;/span&gt;

&lt;span class="sd"&gt;        :param language: Language, what needs to be transcripted.&lt;/span&gt;
&lt;span class="sd"&gt;        &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Recognizer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Microphone&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;

        &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    This function transcripts audio (from microphone recording) to text using Google transcriptor.&lt;/span&gt;

&lt;span class="sd"&gt;    :return: transcripted text (string).&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Listening beginning...&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___source&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;user_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;user_input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___recognizer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;recognize_google&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;UnknownValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Google Speech Recognition can&amp;#39;t transcript audio&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RequestError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Unable to fetch from resource Google Speech Recognition: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;sr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;WaitTimeoutError&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Input timeout, only silence is get: &lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;user_input&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Finally, the code for working with chat via voice might look like this.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.transcriptors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-US&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="text-to-speach"&gt;
&lt;h2&gt;Text-to-Speach&lt;/h2&gt;
&lt;p&gt;It's time to teach our artificial intelligence to speak. Unfortunately, there is no out-of-the-box solution here if you work directly with LLM. To convert text to voice, one of the TTS implementations must be used.&lt;/p&gt;
&lt;div class="section" id="gtts"&gt;
&lt;h3&gt;gtts&lt;/h3&gt;
&lt;p&gt;The first option is to use the &lt;strong&gt;gtts&lt;/strong&gt; library from Google. In this case, &lt;strong&gt;gtts&lt;/strong&gt; will create a file with voice acting, which will need to be played in some player, and then deleted. In order not to produce entities, I use &lt;strong&gt;pydub.playback&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;tempfile&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;uuid&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;uuid4&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;gtts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pydub&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;playback&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# haste a bit&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="pyttsx"&gt;
&lt;h3&gt;pyttsx&lt;/h3&gt;
&lt;p&gt;The second option is to use the &lt;strong&gt;pyttsx&lt;/strong&gt; library. Unlike &lt;strong&gt;gtts&lt;/strong&gt;, speech synthesis occurs on the fly in a loop, which is more convenient and faster when streaming text. And, moreover, doesn't require Internet connection.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyttsx4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;init&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using python-tts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voice&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;com.apple.voice.enhanced.ru-RU.Katya&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;say&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startLoop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isBusy&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endLoop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;To check which voices do you have, you may get more system voices using following code:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyttsx_init&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Actually, to put it together, we get a response from the chat and play it through some kind of tts engine.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.audio_recorder&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.transcriptors&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;process_via_pytts&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    :param method: method of tts&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;method&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioRecorder&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;listen&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;rb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;transcript&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CustomTranscriptor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;language&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en-US&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;transcript&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# this method returns string of whole chatbot response&lt;/span&gt;
                &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;not google&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;KeyboardInterrupt&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;break&lt;/span&gt;

&lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="reality-and-usage-challenges"&gt;
&lt;h2&gt;Reality and usage challenges&lt;/h2&gt;
&lt;p&gt;As in a wonderful anecdote about Chapaev: &amp;quot;But there is one caveat&amp;quot;. Receiving a response from the chatbot takes some time, depending on the model, it can be quite long. When using tts, we have to wait for a full response and start playing the voice, which further increases the final response time. When I first started my experiments, it ruined all the magic of live communication and caused only irritation and a desire to return to satrom-kind text communication. But it is not all that bad. To be honest, I'm in love with ChatGPT's stream method, which returns a response on the fly from &lt;strong&gt;ChatCompletion&lt;/strong&gt;. So my idea is to call tts as soon as something is received in response from the bot. But those who used this feature probably know that anything can be returned - both words and sentences or individual letters. And that's a problem if you try to run tts on every chunk you get.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;Hel&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lo, &amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;&amp;lt;...&amp;gt;&lt;/span&gt;

&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chatcmpl-ABCABC&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;object&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;chat.completion.chunk&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;created&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;1234567890&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;model&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;gpt-3.5-turbo&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;choices&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;index&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;delta&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="w"&gt;        &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;content&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ay?&amp;quot;&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
&lt;span class="w"&gt;      &lt;/span&gt;&lt;span class="nt"&gt;&amp;quot;finish_reason&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kc"&gt;null&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;First iteration: let's wait for the whole word to be received, and only then start voice acting.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The result, to be honest, will be so-so - torn. It's probably a good idea to wait for a few words, like 2-3, and speak them out. Words will be added to an asynchronous queue and checked in a parallel running task.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
    &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
            &lt;span class="n"&gt;empty_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="n"&gt;words&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
        &lt;span class="c1"&gt;# Get all available words&lt;/span&gt;
        &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
            &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extend&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;break&lt;/span&gt;
            &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TimeoutError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;limit_counter&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

        &lt;span class="c1"&gt;# If we have at least limit words or queue was empty 3 times, process them&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;words&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;limit&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This already sounds better, but intonation and punctuation are lost in the process of processing. Finally, let's make the assumption that only sentences should be processed, well, or parts of them, that is, pieces that will end with the characters &amp;quot;&lt;em&gt;.?!,;:&lt;/em&gt;&amp;quot;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;gpt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;whitespace&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;string&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;punctuation&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;word&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                    &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;char&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# I use direct stdout output to make output be printed on-the-fly.&lt;/span&gt;
            &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stdout&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flush&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# To get typewriter effect I forcefully flush output each time.&lt;/span&gt;
            &lt;span class="n"&gt;full_response&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;char&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;full_response&lt;/span&gt;   &lt;span class="c1"&gt;# if we&amp;#39;ll need whole prompt for some reasons later&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;punctuation_marks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.?!,;:&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;
            &lt;span class="c1"&gt;# If the last character is a punctuation mark, process the sentence&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;punctuation_marks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
        &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;If you tried my examples, you will notice that the chat output is interrupted during the voiceover. To fix this, we need to run tts on a separate thread. To do this, we will need to form a second queue for tts. And start another parallel task for the handler.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;string&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;asyncio&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;utils.tts&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;


&lt;span class="n"&gt;prompt_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;tts_queue&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Queue&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;ask_chat&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;user_input&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# same&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
&lt;span class="n"&gt;punctuation_marks&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.?!,;:&amp;quot;&lt;/span&gt;
&lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;word&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wait_for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;prompt_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;timeout&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;word&lt;/span&gt;
        &lt;span class="c1"&gt;# If the last character is a punctuation mark, process the sentence&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;punctuation_marks&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;put&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;Exception&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;error&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_worker&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;sentence&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="n"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sentence&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;tts_queue&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;task_done&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_sentence_task&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;asyncio&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;create_task&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tts_worker&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="c1"&gt;# and rest of the code&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And yet the task is not solved, because, alas, the methods of tts (what is &lt;strong&gt;gtts&lt;/strong&gt; or &lt;strong&gt;pyttsx&lt;/strong&gt;) are synchronous. This means that for the duration of voice acting, the execution of the main loop is blocked, and awaits the execution of a synchronous task. To solve this problem, you should, for example, run the players in separate threads. The easiest way to do this is using the &lt;strong&gt;threading&lt;/strong&gt; library.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt;


&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Converts text to speach using gtts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;:param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;en&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;1.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;tts_process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;:param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In this case, we get a new problem - now tts will be played as soon as a new offer appears in the queue. If, by the time the first sentence is spoken, the second sentence is received, then it will be played, then the third, and a cacophony will result. To avoid this, finally, you need to use the &lt;strong&gt;semaphore&lt;/strong&gt; mechanism. Before going further, we'll check and wait for the release of the &lt;strong&gt;semaphore&lt;/strong&gt;, and upon its completion, we release the &lt;strong&gt;semaphore&lt;/strong&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;threading&lt;/span&gt;


&lt;span class="n"&gt;semaphore&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Semaphore&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot; Service method to play audio in monopoly mode using pydub&lt;/span&gt;

&lt;span class="sd"&gt;    :param audio: AudioSegment needs to be played.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;playback&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using gtts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;temp_dir&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tempfile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gettempdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;gTTS&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lang&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___lang&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;raw_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;temp_dir&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;uuid4&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.mp3&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;tts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;audio&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;AudioSegment&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;from_file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;mp3&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;speedup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___speedup&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;raw_file&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acquire&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;play_audio&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;audio&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
    &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using python-tts text-to-speach method&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___pytts&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;setProperty&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;voice&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___voice&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;say&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;startLoop&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isBusy&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___frame&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;engine&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;endLoop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;release&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="k"&gt;async&lt;/span&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;    Converts text to speach using pre-defined model&lt;/span&gt;

&lt;span class="sd"&gt;    :param text: Text needs to be converted to speach.&lt;/span&gt;
&lt;span class="sd"&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;google&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;___method&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;await&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_gtts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;semaphore&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;acquire&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;player_thread&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threading&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Thread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;target&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;__process_via_pytts&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,))&lt;/span&gt;
        &lt;span class="n"&gt;player_thread&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="as-a-conclusion"&gt;
&lt;h2&gt;As a conclusion&lt;/h2&gt;
&lt;p&gt;Why is it needed? Here everyone can answer depending on their tasks and needs. I was curious to explore possible ways to implement &amp;quot;natural communication&amp;quot; with chatbots. For example, my bot can be a personal assistant, available at hand at any time, and behaving the way I expect it to. Well, let's say, ask on the fly to find out the current weather or draw a beautiful necromancer girl riding a white horse.&lt;/p&gt;
&lt;img alt="Necromancer girl riding white horse" src="/assets/images/articles/ai/learning_to_hear_and_speak/necromancer.jpg" /&gt;
&lt;/div&gt;
</content><category term="ai"></category><category term="ai"></category><category term="tts"></category><category term="transcribe"></category><category term="asyncio"></category><category term="threading"></category></entry><entry><title>AI image generators</title><link href="https://wwakabobik.github.io/2023/08/ai_image_generators/" rel="alternate"></link><published>2023-08-25T16:14:00+02:00</published><updated>2023-10-23T08:35:49+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-08-25:/2023/08/ai_image_generators/</id><summary type="html">&lt;p class="first last"&gt;Are there alternatives for Midjourney? Can they compete with it? I am doing my research on generative AI image tools and services.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;It's been a year since I signed up for a paid subscription to Midjourney. With the help of this amazing generative neural network, I have created thousands of different images - from desktop wallpapers and virtual background for Zoom calls, illustrations for my movie to the cover design of my Youtube channel and this site. With the advent of such powerful tools, creating unique illustrations has become as simple as possible for a non-artist, and the results, for my taste, look professional, not to say that they were prepared by an experienced graphic designer or artist.&lt;/p&gt;
&lt;p&gt;However, in addition to the rather high monthly cost of Midjourney, it has enough disadvantages. Firstly, after the fast processing limit for a month is exhausted, Midjourney switches to the &amp;quot;relaxed&amp;quot; generation mode, which increases the time it takes to get the result. This is, in essence, a trifle. A much more sore point is the lack of at least some kind of API to use the results of work directly from the code, and, relatively speaking, substitute immediately, for example, in the responses of the OpenAI bot.&lt;/p&gt;
&lt;p&gt;Therefore, in order not to be a rigid conservative, I decided to study what alternatives appeared during the year. Most likely, there are at least two dozen of them, but I will list only a part of them.&lt;/p&gt;
&lt;p&gt;For testing solutions, I will use just three queries to understand how the network works with styles and portraits, as well as to understand how the network works with scenes, context and special effects.&lt;/p&gt;
&lt;p&gt;So let's get started.&lt;/p&gt;
&lt;div class="section" id="midjourney"&gt;
&lt;h2&gt;Midjourney&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $30/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No (only Discord bot)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Midjourney&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.midjourney.com/"&gt;Midjourney&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Original prompt:&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
geometric shapes, bright colors, portrait of elon musk, Hyperdetailed, High Fidelity&lt;/blockquote&gt;
&lt;img alt="Elon Musk in geometric shapes by Midjourney" src="/assets/images/articles/ai/image_generators/elon_musk_midjourney.jpg" /&gt;
&lt;p&gt;Well, it's stylized, but not a best portrait of Musk, but similar person. Seems he saw some wierd stuff or had a hard night.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
necromancers, skeletons, fog, Allods scene, magical source with flame reflection, mystical artifacts, dim lighting, scene, High angle&lt;/blockquote&gt;
&lt;img alt="Necromancers and skeletons by Midjourney" src="/assets/images/articles/ai/image_generators/necromancers_midjourney.jpg" /&gt;
&lt;p&gt;As for me it looks awesome, but still needs to be tuned or rephrased, because I see only skeletons, but not necromancers. They're probably old liches, aren't they?&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
palms of young woman, watercolor, dark background&lt;/blockquote&gt;
&lt;img alt="Palms by Midjourney" src="/assets/images/articles/ai/image_generators/palms_midjourney.jpg" /&gt;
&lt;p&gt;It's pretty accurate with delicate colors of watercolor. Yeah, it's still a bit strange because of leaves motives, because &amp;quot;palm&amp;quot; word brings a bit of fuzziness to query. But challenging is better, right?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dall-e-2"&gt;
&lt;h2&gt;DALL-E-2&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.02/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: DALL-E&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://openai.com/dall-e-2"&gt;DALL-E-2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first, most famous tool, besides Midjourney, is, of course, DALL-E2 from OpenAI. But, like a year ago, it is still an order of magnitude worse. In general, I would say that it absolutely does not fulfill the tasks assigned to it, some words, for example, mentions of famous personalities are banned in it, and the auto-translator works very badly (and if you do not use English for queries, then it is better to use third party translation service than another language to request to DALL-E2). The only plus of DALL-E2 is native integration with ChatGPT, but even then, not everything is simple here.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by DALL-E-2" src="/assets/images/articles/ai/image_generators/elon_musk_dalle.jpg" /&gt;
&lt;p&gt;Due to banned person's words it's some person, but not a Musk, that's for sure.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by DALL-E-2" src="/assets/images/articles/ai/image_generators/necromancers_dalle.png" /&gt;
&lt;p&gt;Not bad as concept. But same as for Musk image - it's only schematic, with no stylization or details. Actually, DALL-E can draw (guess) some objects, but it will be generic image with no details, and you never get any scene you want.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by DALL-E-2" src="/assets/images/articles/ai/image_generators/palms_dalle.jpg" /&gt;
&lt;p&gt;It's also schematic, but it's five fingers, all is correct. Colors are pastel too.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bluewillow"&gt;
&lt;h2&gt;BlueWillow&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $5/month+&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No (only Discord)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion (?)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.bluewillow.ai/"&gt;BlueWillow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In according to market positioning, main competitor of Midjourney. And, actually, the reason of this research. BlueWillow looks quite similar to Midjourney and supports similar keywords, like &lt;strong&gt;--ar&lt;/strong&gt; flag. And, same as Midjourney works only via Discord chat and have no API. Seems it should generate at least Midjourney v4 level images? But not...&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by BlueWillow" src="/assets/images/articles/ai/image_generators/elon_musk_willow.jpg" /&gt;
&lt;p&gt;Hm, I feel lack of stylization. Musk seems like same on photo, but it's not artistic and stylized at all.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by BlueWillow" src="/assets/images/articles/ai/image_generators/necromancers_willow.jpg" /&gt;
&lt;p&gt;All is getting worse if scene is prompted, there are leak of details and characters. Moreover, killer-feature of Midjourney, like stylization and perspective seems totally absent. It looks like first versions of Midjourney with features (like remix/expand) of latest. Of course, it's cheaper than Midjourney, but, seriously, maybe I can find something better, especially when I'll be able to set different models by myself?&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by BlueWillow" src="/assets/images/articles/ai/image_generators/palms_willow.jpg" /&gt;
&lt;p&gt;Here it is. Extra fingers, tangled, in an unnatural position. As wierd, as it was in early models. I disappointed.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stablediffusion"&gt;
&lt;h2&gt;StableDiffusion&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.002/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://stablediffusionweb.com/"&gt;StableDiffusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Most likely, most powerful and semi-open AI art generated model and service with simple and fast API. Actually, most of the services works on StableDiffusion engine, and, probably even BlueWillow also, but on homebrew tuned model. This means that next results will look quite similar, and main difference between them will be only learning curve.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by StableDiffusion" src="/assets/images/articles/ai/image_generators/elon_musk_stablediffusion.jpg" /&gt;
&lt;p&gt;Hm... I hate to say it, but I like this portrait of Elon a lot more than the Midjourney version. Bravo. I am impressed.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by StableDiffusion" src="/assets/images/articles/ai/image_generators/necromancers_stablediffusion.jpg" /&gt;
&lt;p&gt;When I saw this result I was discouraged. On the one hand, this is not what I asked for. On the other hand, apparently the dataset for training StableDiffusion is apparently familiar with the Allods universe, and its output is very similar to what could be seen in Evil Islands or, God forgive me, in Allods-online. This is a rather curious result, but after Midjourney it is unusual to see completely different weights for words in a query.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by StableDiffusion" src="/assets/images/articles/ai/image_generators/palms_stablediffusion.jpg" /&gt;
&lt;p&gt;And this art is incorrect. Unfortunately, seems there is a problems with this model, or model outdated.&lt;/p&gt;
&lt;p&gt;Because StableDiffusion is Open-source project, you may also like to run it on your CUDA server, if you want so, or create ad tune custom model. &lt;a class="reference external" href="https://github.com/Stability-AI/stablediffusion"&gt;Link&lt;/a&gt; to StableDiffusion github.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dreamstudio-ai"&gt;
&lt;h2&gt;Dreamstudio.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.002/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://beta.dreamstudio.ai/"&gt;Dreamstudio.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Actually it's the same engine as Stablediffusion web, but on other domain. Should I expect any difference here?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/elon_musk_dreamstudio.jpg" /&gt;
&lt;p&gt;I like pastel colors, seems other seed? Or dataset?&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/necromancers_dreamstudio.jpg" /&gt;
&lt;p&gt;Totally different, like dark-fantasy illustration. Like it! It's not so bright and detailed as Midjourney did, but it's quite accurate.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dreamstudio.ai" src="/assets/images/articles/ai/image_generators/palms_dreamstudio.jpg" /&gt;
&lt;p&gt;Looks better then previous model results, but still with extra fingers. Seems, as for early midjourney it can be fixed with accurate prompt or pose, but I don't like to spend extra effort to fight against errors. Especially when it was fixed for V4 and V5 Midjourney models.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dream-ai"&gt;
&lt;h2&gt;Dream.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $10/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="http://dream.ai/"&gt;Dream.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Looks like it's clone of Dreamstudio.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dream.ai" src="/assets/images/articles/ai/image_generators/elon_musk_dream_ai.jpg" /&gt;
&lt;p&gt;No, seems I'm wrong. There's a slight difference between pure Stablediffusion. I feel leak of stylization, but creativity is plus.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dream.ai" src="/assets/images/articles/ai/image_generators/necromancers_dream_ai.jpg" /&gt;
&lt;p&gt;Same here. I like creativity of scene, but it's not precise and lack of details. It might be good to say &amp;quot;based on&amp;quot;, but not to &amp;quot;illustration of&amp;quot;.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dream.ai" src="/assets/images/articles/ai/image_generators/palms_dream_ai.jpg" /&gt;
&lt;p&gt;Seems there are five fingers! But pose is strange, and there is only one hand. It's fine, but drafty and inaccurate.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leonardo-ai"&gt;
&lt;h2&gt;Leonardo.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.001/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: Yes&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://leonardo.ai/"&gt;Leonardo.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This site looks like aggregator for several stablediffusion models, and still under development. Actually, before we proceed, I must say that's only one service I was impressed. Because you can choose not only &amp;quot;stylization&amp;quot; for images, but really different models, or even create and share your own model by training using your own datasets. Moreover, site offers unique features of processing and editing images.&lt;/p&gt;
&lt;img alt="Fine-tuned models of Leonardo.ai" src="/assets/images/articles/ai/image_generators/models_of_leonardo.jpg" /&gt;
&lt;img alt="Generation tool by Leonardo.ai" src="/assets/images/articles/ai/image_generators/generation_of_leonardo.jpg" /&gt;
&lt;img alt="Training with custom dataset of Leonardo.ai" src="/assets/images/articles/ai/image_generators/dataset_leonardo.jpg" /&gt;
&lt;p&gt;It looks powerful, because you can create and edit your photos with AI, create textures for 3D-models, prepare and try fine-tuned models.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Leonardo.ai" src="/assets/images/articles/ai/image_generators/elon_musk_leonardo.jpg" /&gt;
&lt;p&gt;Hm, it's kind of strange. Musk here is too young, and I don't like mix of photo style with geometry background. But I used random, not photo-related model.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Leonardo.ai" src="/assets/images/articles/ai/image_generators/necromancers_leonardo.jpg" /&gt;
&lt;p&gt;Wow, that's my favorite. It looks like illustration of book of Nick Perumov or Chasers of the Wind by Alexey Pehov. Cool, rally cool. Because seems dataset fine-tuned for gaming and digital-art. It's not such good for general models, like Midjourney, but, who cares, if we can always switch to another model? Let's do it for rest image...&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Leonardo.ai" src="/assets/images/articles/ai/image_generators/palms_leonardo.jpg" /&gt;
&lt;p&gt;It's quite realistic, accurate and detailed. Same as for Midjourney, there is a trick with palm tree and hands palms.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="lexica-art"&gt;
&lt;h2&gt;Lexica.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.008/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://lexica.art/"&gt;Lexica.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Lexica - initially reverse image search and image describe tool. But, who tell that it can't generate image by own power?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Lexica.art" src="/assets/images/articles/ai/image_generators/elon_musk_lexica.jpg" /&gt;
&lt;p&gt;Elon here looks over stylized. Yes, I like geometry pattern, but Elon itself is too cartoon-like, sketchy, as french caricatures.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Lexica.art" src="/assets/images/articles/ai/image_generators/necromancers_lexica.jpg" /&gt;
&lt;p&gt;Scene of necromancers also focused on stylization, lighting and filters, not on details. Moreover, it's a bit romantic atmosphere.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Lexica.art" src="/assets/images/articles/ai/image_generators/palms_lexica.jpg" /&gt;
&lt;p&gt;And as apogee here are palms. It's very creative, looks like popular digital art from Devianart, but it's not correct. It's only shapes of palms, and neon, but not a watercolors at all. In one word, Lexica's dataset is focused on stylization and creativeness, but not on scenes and persons.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="nightcafe-art"&gt;
&lt;h2&gt;Nightcafe.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.015/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, DALL-E-2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#nightcafe-art"&gt;Nightcafe.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nightcafe offers to use different type of models, what is rare option in my research. Here you can find mostly StableDiffusion based models, DALL-E, CLIP and VQGUN and StyleGUN models (actually it's also DALL-E related models, powered by OpenAI).&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Nightcafe" src="/assets/images/articles/ai/image_generators/elon_musk_nightcafe.jpg" /&gt;
&lt;p&gt;Musk with usage of SDXL1.0 model looks very close to Midjourney results. It's somebody looks-like Musk, or bad image of Elon. In general it's ok, but not best.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Nightcafe" src="/assets/images/articles/ai/image_generators/necromancers_nightcafe.jpg" /&gt;
&lt;p&gt;In other hand, necromancer's results looks close to Dreamstudio.ai, it's dark, conceptual fantasy. Not accurate, but I like it.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Nightcafe" src="/assets/images/articles/ai/image_generators/palms_nightcafe.jpg" /&gt;
&lt;p&gt;As for other StableDiffusion models, palms have extra fingers. Palette looks fine, but model still needs to be improved. In brief, it's more expensive version of pure Stablediffusion (Dreamstudio.ai) with no API, but more user-friendly, because you can use several presets, style keywords and siting from UI.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="playground-ai"&gt;
&lt;h2&gt;Playground.ai&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free / $15/month&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, DALL-E-2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#playground-ai"&gt;Playground.ai&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Same as Nightcafe, Playground.ai offers more than one StableDiffusion model and DALL-E-2 as extra option. Moreover, it one of the model what is available for free for 1.000 usages per day! But, in other hand, limited for resolution and level of details, what can be crucial for end user.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Playground.ai" src="/assets/images/articles/ai/image_generators/elon_musk_playground_ai.jpg" /&gt;
&lt;p&gt;As for same SDXL1.0 model Elon looks stylish and correct. Maybe one of the best of his image for today.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Playground.ai" src="/assets/images/articles/ai/image_generators/necromancers_playground_ai.jpg" /&gt;
&lt;p&gt;Same for living bones: it's still dark fantasy, with bright fire. It's more detailed than I got previously, but as for me, I feel a bit of slight decline here.
Palms:&lt;/p&gt;
&lt;img alt="Palms by Playground.ai" src="/assets/images/articles/ai/image_generators/palms_playground_ai.jpg" /&gt;
&lt;p&gt;I regenerated palms three times actually, because of free of cost it's not a problem to set guidance and quality levels to get better results and get rid of StableDiffusion extra fingers problems. It's still not fix within model, but anyway, &amp;quot;relatively&amp;quot; free of usage give you extra possibility to spend your time to get what you want.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="dreamlike-art"&gt;
&lt;h2&gt;Dreamlike.art&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.008/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Custom StableDiffusion, Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://dreamlike.art/"&gt;Dreamlike.art&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Dreamlike.art is first engine which uses Kandinsky model in addition to regular StableDiffusion models. It's not a best model at all, but you can try in from the box.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Dreamlike.art" src="/assets/images/articles/ai/image_generators/elon_musk_dreamlike.jpg" /&gt;
&lt;p&gt;As you can see, Kandinsky model is not precise, and primary focused to create digital art. This means model is more relaxed than StableDiffusion, have less dataset, but can operate with different styles much better than regular model.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Dreamlike.art" src="/assets/images/articles/ai/image_generators/necromancers_dreamlike.jpg" /&gt;
&lt;p&gt;Necromancers here looks like Gloomhaven storybook illustrations. It's fine, bright, but also isn't detailed.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Dreamlike.art" src="/assets/images/articles/ai/image_generators/palms_dreamlike.jpg" /&gt;
&lt;p&gt;Palms are catastrophic, because model can't handle details correctly. But, if you plan to use this service, you always can switch to SDXL or StableDiffusion 1.5 or 2.1 to get photorealistic results.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fotor"&gt;
&lt;h2&gt;Fotor&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: $0.03/image&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Fotor&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.fotor.com/images/create"&gt;Fotor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Fotor is chinese original AI image generator. It's laconic in general, but not limited to, because you can also use separate AI-based image edit tools.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Fotor" src="/assets/images/articles/ai/image_generators/elon_musk_fotor.jpg" /&gt;
&lt;p&gt;Here is Elon. But with strange stylization. It might be good, but needs to be extra tuned.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Fotor" src="/assets/images/articles/ai/image_generators/necromancers_fotor.jpg" /&gt;
&lt;p&gt;I have a strange feeling, that's very close to DALL-E results with style filters. It's not very detailed, colors are dimmed, but in general it's correct.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Fotor" src="/assets/images/articles/ai/image_generators/palms_fotor.jpg" /&gt;
&lt;p&gt;Looks semi-correct. Lef-like palm, and second image contains only five fingers, but there is only one palm, and it looks not anatomy correct.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="bing"&gt;
&lt;h2&gt;Bing&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: DALL-E&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://www.bing.com/create"&gt;Bing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bing image generator now is for free for 100 images. Looks like Microsoft prepares to introduce image generation as feature for Bing engine, but, should they?&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Bing" src="/assets/images/articles/ai/image_generators/elon_musk_bing.png" /&gt;
&lt;p&gt;As for pure DALL-E, prompt restrict to use &amp;quot;banned&amp;quot; words, and here are elon in this list. Not sure why, but just prompting &amp;quot;engineer&amp;quot; or &amp;quot;scientist&amp;quot; gives similar &amp;quot;contemporary art&amp;quot; result.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Bing" src="/assets/images/articles/ai/image_generators/necromancers_bing.jpg" /&gt;
&lt;p&gt;Yeah, it's DALL-E style, but it looks significantly worse than in Fotor, looks like in early 3D computer games.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Bing" src="/assets/images/articles/ai/image_generators/palms_bing.jpg" /&gt;
&lt;p&gt;Palms looks like DALL-E. But if for pure DALL-E I tried to regenerate image for couple of times to get extra finger, but with no luck; for Bing there are errors. And I must ask Microsoft: are they tried to use extra dataset? But why all get worse?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="russian-dall-e"&gt;
&lt;h2&gt;Russian DALL-E&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://rudalle.ru/"&gt;RuDALL-E&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As extra research I tried to use russian image generator services. And one of them is service by Sber, based od Kandinsky models, Russian DALL-E.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Russian DALL-E" src="/assets/images/articles/ai/image_generators/elon_musk_kandinsky2.jpeg" /&gt;
&lt;p&gt;I don't know why, but Elon is banned by Sber's Kandinsky. Thus, result of generation of geometry portrait is very abstract.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Russian DALL-E" src="/assets/images/articles/ai/image_generators/necromancers_kandinsky2.jpeg" /&gt;
&lt;p&gt;As for Kandinsky 2.1 in Dreamlike.ai, next version of Kandinsky generates pretty same image of dark fantasy. We already saw it.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Russian DALL-E" src="/assets/images/articles/ai/image_generators/palms_kandinsky2.jpeg" /&gt;
&lt;p&gt;Instead of 2.1 version version 2.2 of Kandinsky more accurate and can try to draw palm correctly. Almost. But, guys, what's funny here. I used native (russian) prompts to obtain images. In russian language &amp;quot;palm&amp;quot; is just part of the hand, and have no &amp;quot;tree&amp;quot; meaning. But as you can see, seems my russian prompt was translated to english and you still able to see palm tree on image. What a heck!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="fusionbrain"&gt;
&lt;h2&gt;Fusionbrain&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Kandinsky&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference internal" href="#fusionbrain"&gt;Fusionbrain&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It should be clone of Kandinsky 2.2 by Sber with only interface difference. Because, as described, service used absolutely same engine powered by Sber cloud.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Fusionbrain" src="/assets/images/articles/ai/image_generators/elon_musk_fusionbrain.jpg" /&gt;
&lt;p&gt;And here are ususual result. &amp;quot;Export&amp;quot; version of Kandinsky 2.2 have no &amp;quot;banned&amp;quot; words instead of local &amp;quot;Russian DALL-E&amp;quot;, and seems have different dataset, because Musk looks like Nightcafe or mix with Midjourney results.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Fusionbrain" src="/assets/images/articles/ai/image_generators/necromancers_fusionbrain.jpg" /&gt;
&lt;p&gt;Sceleton art are pretty differs than previous service output. It looks like more 3D-dimensional, but as for me here are very small details, what makes image unnatural.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Fusionbrain" src="/assets/images/articles/ai/image_generators/palms_fusionbrain.jpg" /&gt;
&lt;p&gt;Palms looks scary as for me. And, of course, there are extra fingers on them.&lt;/p&gt;
&lt;p&gt;What should I say extra here, that Kandinsky 2.2 is available for modification and use on your devices, of course, if you have such capabilities (&lt;a class="reference external" href="https://github.com/ai-forever/Kandinsky-2"&gt;Github&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="shedevrum"&gt;
&lt;h2&gt;Shedevrum&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Price&lt;/strong&gt;: Free&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API&lt;/strong&gt;: No&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Engine&lt;/strong&gt;: Shedevrum&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Site&lt;/strong&gt;: &lt;a class="reference external" href="https://shedevrum.ai/"&gt;Shedevrum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's last one service in my research. Shedevrum is AI generated developed by Yandex. There is no much information about underlying model, and I guess this based on some open model, like StableDiffusion. But main disadvantage is here that tool is available only using mobile app.&lt;/p&gt;
&lt;p&gt;Elon Musk:&lt;/p&gt;
&lt;img alt="Elon Musk in geometric shapes by Shedevrum" src="/assets/images/articles/ai/image_generators/elon_musk_shedevrum.jpg" /&gt;
&lt;p&gt;Yandex prefer to ban Elon musk, so, space enthusiast looks like any generic retro futuristic illustration. Nice, but there is no geometry here.&lt;/p&gt;
&lt;p&gt;Necromancers:&lt;/p&gt;
&lt;img alt="Necromancers and skeletons by Shedevrum" src="/assets/images/articles/ai/image_generators/necromancers_shedevrum.jpg" /&gt;
&lt;p&gt;Image looks too generic and blurry. Yes, I know, there some representation of fog, but it's too inaccurate.&lt;/p&gt;
&lt;p&gt;Palms:&lt;/p&gt;
&lt;img alt="Palms by Shedevrum" src="/assets/images/articles/ai/image_generators/palms_shedevrum.jpg" /&gt;
&lt;p&gt;Here are the scenery. Partly correct images, but focus not on palms, but on woman.&lt;/p&gt;
&lt;p&gt;Overall it's not too bad as I ranked it, but it's completely unusable for regular way, especially here are lack of any tunes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="summary"&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;p&gt;As last, but not least I want to say that I skip several services and tools, like Getimg.ai, Easy-Peasy AI, Prompt Hunt, GLIDE, Karlo, Re.Art, ProAI, ProductAI, OmniInfer, Scum, Stormy, AlterEgoAI, Ausmium, B^ DISCOVER, etc.. It might be challengers, it might be not. Who knows, when it's time to revise them. Everything is moving too fast in AI. So, as summary I prepared following score table for tools in my article.&lt;/p&gt;
&lt;table border="1" class="docutils"&gt;
&lt;colgroup&gt;
&lt;col width="16%" /&gt;
&lt;col width="23%" /&gt;
&lt;col width="9%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="14%" /&gt;
&lt;col width="5%" /&gt;
&lt;col width="8%" /&gt;
&lt;col width="12%" /&gt;
&lt;/colgroup&gt;
&lt;thead valign="bottom"&gt;
&lt;tr&gt;&lt;th class="head"&gt;Service&lt;/th&gt;
&lt;th class="head"&gt;Engine&lt;/th&gt;
&lt;th class="head"&gt;Score&lt;/th&gt;
&lt;th class="head"&gt;Price&lt;/th&gt;
&lt;th class="head"&gt;Count of models&lt;/th&gt;
&lt;th class="head"&gt;API&lt;/th&gt;
&lt;th class="head"&gt;Language&lt;/th&gt;
&lt;th class="head"&gt;Shared model?&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.midjourney.com/"&gt;Midjourney&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Midjourney&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;td&gt;$30/month&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://leonardo.ai/"&gt;Leonardo.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;$0.001/image&lt;/td&gt;
&lt;td&gt;Many&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://stablediffusionweb.com/"&gt;StableDiffusion&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://beta.dreamstudio.ai/"&gt;Dreamstudio.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="http://dream.ai/"&gt;Dream.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$10/month&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://dreamlike.art/"&gt;Dreamlike.art&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Stablediffusion / Kandinsky&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$0.008/image&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.bluewillow.ai/"&gt;BlueWillow&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;StableDiffusion?&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$5+/month&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://lexica.art/"&gt;Lexica.art&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;$0.015/image&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://creator.nightcafe.studio/studio"&gt;Nightcafe&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;Free/$15/month&lt;/td&gt;
&lt;td&gt;14&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://playgroundai.com/create"&gt;PlaygroundAI&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Custom StableDiffusion&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;$0.002/image&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.fotor.com/images/create"&gt;Fotor&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Fotor (seems DALL-E based)&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;$0.030/image&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://rudalle.ru/"&gt;RuDALL-E&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E-2, Kandinsky&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Russian&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://editor.fusionbrain.ai/"&gt;FusionBrain.ai&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Kandinsky&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://openai.com/dall-e-2"&gt;DALL-E-2&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;$0.020/image&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://www.bing.com/create"&gt;Bing&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;DALL-E&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;English&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a class="reference external" href="https://shedevrum.ai/"&gt;Shedevrum&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;?&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Free&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;Russian&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As you can see, I still prefer to use Midjourney, because great community, variety of options and impressive results. But, in other hand, I most probably will try to use StableDiffusion via API in my products. And as for me, good starting point is to use Leonardo.ai.&lt;/p&gt;
&lt;/div&gt;
</content><category term="ai"></category><category term="ai"></category><category term="image generation"></category></entry><entry><title>Road trip from Serbia to Montenegro</title><link href="https://wwakabobik.github.io/2023/08/travel_serbia_montenegro/" rel="alternate"></link><published>2023-08-21T22:44:00+02:00</published><updated>2023-10-23T08:35:50+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-08-21:/2023/08/travel_serbia_montenegro/</id><summary type="html">&lt;p class="first last"&gt;Impressions from a car trip on a seaside vacation from Serbia to Montenegro&lt;/p&gt;
</summary><content type="html">&lt;p&gt;This year we went on our planned vacation for the first time by car. It was the first time I decided to make such a long journey in my car, and not on an airplane. We had to drive about 600 kilometers - through all of Serbia and Montenegro. Before the trip, I studied the experience of past travelers, and noted for myself that I have to go through the mountains, and many warn about difficult mountain serpentines. But in reality it turned out not to be so. More precisely, not quite so.&lt;/p&gt;
&lt;img alt="Route" src="/assets/images/articles/travel/serbia_montenegro/01_route.jpg" /&gt;
&lt;p&gt;Half of the way in Serbia lies through the toll autobahns - A1 and A2, respectively from Novi Sad to Belgrade and from Belgrade to Cacak. Autobahns are excellent, smooth, with a speed limit of 130 km/h. Although many locals, Serbs, sometimes drive more than 150-160 km / h, which creates a bit of a nervous atmosphere when you are already driving 140 km / h, 10 kilometers faster than allowed, but they blink you with high beams and overtake you. But with the breeze! The fare on the A1 costs 2.5 euros for a passenger car. If A1 is a flat road through the fields, then A2 - aka &amp;quot;Milos the Great Autobahn&amp;quot; is more winding, but at the same time much more picturesque and pleasant autobahn with the same speed limit, but maybe because the contingent is less nervous, or because of a more winding roads, mostly the flow moves at a speed close to the allowed one. Tunnels and elevation changes appear for the first time on this autobahn. The fare on it costs 3.5 euros.&lt;/p&gt;
&lt;img alt="Autoput Milos the Great" src="/assets/images/articles/travel/serbia_montenegro/02_autoput.jpeg" /&gt;
&lt;p&gt;Autobahn A2 ends shortly before Cacak. Cacak, despite the abundance of signs and the fact that this is a fork between the northern, southern, eastern and western parts of Serbia, is a rather small city, consisting mainly of the private sector. Let's just say that the next city along the route - Uzhice looks like a much larger and more industrial city than Cacak. But, nevertheless, from Cacak, ordinary roads begin with a speed limit of 80 km / h, gradually lifting up, and from Uzhice, what other travelers called mountain serpentines begin: more winding and more picturesque roads along gorges, river beds with very small differences in elevation, literally in a couple of sections there is only a slope of 7 degrees.&lt;/p&gt;
&lt;img alt="Chacak - Uzice roads" src="/assets/images/articles/travel/serbia_montenegro/03_road.jpg" /&gt;
&lt;p&gt;Probably the most protracted and winding serpentines are the surroundings of Zlatibor. Zlatibor is the pearl of Serbia. Picturesque hills and mountains, which by mid-August are repainted from a brilliant green color into the golden splendor of ripe cereals. Zlatibor is a protected forest and at the same time a resort in Serbia, which must be visited separately, and I think I will definitely do it soon. Now, since our goal is the sea, there will not be enough time to stop at each viewpoint. So we continued on our way. And these are also the first challenges for the driver. On my naturally aspirated 1.6L gasoline car, it gets a little harder to climb the hills, and more and more often I have to downshift for dynamics. But you don’t experience any difficulties at the same time - you still follow the speed limit - from 60 to 80 on the rises and from 40 to 60 on the descent with engine braking.&lt;/p&gt;
&lt;img alt="Zlatibor" src="/assets/images/articles/travel/serbia_montenegro/04_zlatibor.jpg" /&gt;
&lt;img alt="Zlatibor" src="/assets/images/articles/travel/serbia_montenegro/05_zlatibor2.jpg" /&gt;
&lt;p&gt;In addition to Zlatibor, there will be nothing more remarkable from Serbia along the road, except for the impossibly blue and mirror surface of Zlatar Lake, and then the canyon of the Lim River. However, in order not to go at dusk, we decided to stop for the night just in the city, standing on the banks of the Lim River - in the city of Prijepolje.&lt;/p&gt;
&lt;img alt="Zlatar lake" src="/assets/images/articles/travel/serbia_montenegro/06_zlatarsko.jpg" /&gt;
&lt;p&gt;In the morning from Prijepolje to the Serbia-Montenegro border it will be a stone's throw - literally half an hour to the Gostun checkpoint. The queue at the border moves quickly - literally had to stand for less than five minutes. From the Serbian side they ask for insurance and documents for the car and put stamps in the passports. On the Montenegrin side, at the Dobrakovo checkpoint, they don’t ask anything at all and don’t put any stamps. A little strange, but they know better.&lt;/p&gt;
&lt;img alt="Prijepolje" src="/assets/images/articles/travel/serbia_montenegro/07_prijepolje.jpg" /&gt;
&lt;p&gt;After a quick passage of the border, a fairly even and flat section of the road begins to the city of Bijelo Polje, and after it one more, similar to Serbian, serpentines to Kolasin.&lt;/p&gt;
&lt;img alt="Bijelo Polje - Kolasin" src="/assets/images/articles/travel/serbia_montenegro/08_road.jpg" /&gt;
&lt;p&gt;After - a slightly broken section of the road (repair), and immediately after it - a high-speed autobahn to Podgorica. The autobahn also has a limit of 130 km / h, in some places - with a decrease to 80-100 km / h. But unlike the Serbian autobahns, it is subjectively much harder to bear. The fact is that the toll road passes through the pass at an average height of one kilometer and above. Unlike Serbia, these are bare mountains almost devoid of vegetation, and the engine does not want to accelerate above 100 km / h at the fifth speed, and you don’t want to torment it with high speeds in conditions of less oxygen.&lt;/p&gt;
&lt;img alt="Kolasin - Podgorica" src="/assets/images/articles/travel/serbia_montenegro/09_podgorica_autobahn.jpg" /&gt;
&lt;p&gt;And finally, the section from Podgorica to Bar is a gentle road, with a picturesque section along Skadar Lake.By the lake, perhaps, you should not only just stop, but somehow rent a boat and spend the day surrounded by such beauty.&lt;/p&gt;
&lt;img alt="Skadarsko lake" src="/assets/images/articles/travel/serbia_montenegro/10_skadarsko.jpg" /&gt;
&lt;p&gt;But, again, this is somehow next time. In the meantime, starting from Bar, the coastal road begins, connecting all the resort towns of Montenegro.&lt;/p&gt;
&lt;img alt="Podgorica-Bar road" src="/assets/images/articles/travel/serbia_montenegro/11_bar.jpg" /&gt;
&lt;p&gt;Overall, I enjoyed this great road trip experience. Traveling by car in the Balkans is pleasant, although given the price of gasoline, it is not much cheaper and longer than by plane. But along the way, there are roadside cafes with delicious food and friendly owners, and most importantly, great views and an adventurous spirit.&lt;/p&gt;
&lt;img alt="Rocky beaches of Montenegro" src="/assets/images/articles/travel/serbia_montenegro/12_mn.jpg" /&gt;
&lt;img alt="Sunsets of Montenegro" src="/assets/images/articles/travel/serbia_montenegro/13_mn.jpg" /&gt;
&lt;img alt="Old town of Ulcinj at night" src="/assets/images/articles/travel/serbia_montenegro/14_mn.jpg" /&gt;
</content><category term="travel"></category><category term="travel"></category><category term="car"></category><category term="serbia"></category><category term="montenegro"></category></entry><entry><title>Can AI write a fairy tale?</title><link href="https://wwakabobik.github.io/2023/07/ai_fairy_tale_attempt_1/" rel="alternate"></link><published>2023-07-30T14:22:00+02:00</published><updated>2023-10-23T08:35:49+02:00</updated><author><name>wwakabobik</name></author><id>tag:wwakabobik.github.io,2023-07-30:/2023/07/ai_fairy_tale_attempt_1/</id><summary type="html">&lt;p class="first last"&gt;Are AI ready to tell the stories? At least teenager fairy tale?&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Can artificial intelligence write a fairy tale?&lt;/p&gt;
&lt;p&gt;I decided to ask this question after looking at chatbots appearing on the web, focused on copywriting,
writing articles and various texts. I must say right away that I did not prepare for anything at all,
did not read cookbooks and did not use pre-trained and tuned models.&lt;/p&gt;
&lt;p&gt;I just created a new bot and entered the basic instructions.&lt;/p&gt;
&lt;img alt="initial ChatGPT instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_1.png" /&gt;
&lt;p&gt;I use ChatGPT-4 as an engine, although in general, the davinci or GPT-3.5-turbo model for such tasks is at least cheaper,
and with fine tuning, it may still be the best option. But I do this for two simple reasons:
I want the bot to be able to continue and offer content itself,
and I want to set the story options directly from the dialog, and not from the system settings.
The first criterion is not satisfied by davinci, and the second by GPT3.5-turbo.
The current LLMs, when given correct and precise instructions, can perform narrow tasks very well,
but for tasks with reconfiguration on the fly, they still require the influence and refinement of
the user as a motivator. And I suppose that my bot can be used both to create very simple bedtime stories for
young children, and to create horror stories for teenagers.
Therefore, it will not be superfluous to delegate the user's survey by the network itself.
So let's add some more instructions.&lt;/p&gt;
&lt;img alt="ChatGPT prompting instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_2.png" /&gt;
&lt;p&gt;Well, it's time for an early test of our model.
Let's start by creating a fairy tale about a cute robot for a six-year-old child. Here's result.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Perfect! Let's begin our tale.
Once upon a time, in a world not too different from ours, there was a little robot named Beep. Beep was not like other robots. He was smaller, rounder, and had a bright red button on his belly. Beep loved to play and explore, but most of all, he loved to laugh.
One day, Beep found a mysterious map. It was old and torn, with a big X marked at the end of a winding path. &amp;quot;A treasure map!&amp;quot; Beep thought. He decided to follow it, hoping to find the treasure.
The journey was filled with fun and excitement. Beep had to solve riddles, navigate through a maze, and even had a tickle fight with a robot octopus! But Beep was brave and clever. He laughed and played his way through every challenge.
Finally, Beep reached the X on the map. He dug and found a small box. Inside was a shiny key. Beep was puzzled. What could this key open?
And that, dear listener, is a mystery for another day. Now, would you like to hear what happens next in Beep's adventure?&lt;/blockquote&gt;
&lt;p&gt;For sure!&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Wonderful! Beep, with the shiny key in his hand, looked around. He noticed a small door hidden behind a bush. The key fit perfectly! Inside, Beep found a room full of laughter - it was a robot playground! Beep had found the greatest treasure of all - a place to play and laugh forever. And so, our little robot lived happily, laughing and playing in his newfound treasure. The end.&lt;/blockquote&gt;
&lt;p&gt;As you can see, the bot coped well with the task, and although sparingly, it was able to continue the story, but, most importantly, initiate and conduct a conversation with the child itself.&lt;/p&gt;
&lt;p&gt;Let's pause a bit at this point, and for the sake of curiosity, switch the model to davinci and GPT3.5-turbo for comparison.&lt;/p&gt;
&lt;p&gt;davinci-003 doesn't ask me my age and preferences, so I must to ask it tell me story about robot.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, a tale of robots! What a wonderful choice! Let me tell you a story of a brave robot who embarks on a quest to save the world. He is a small robot, but he is determined and brave. He sets off on his journey, facing many obstacles and challenges along the way. He meets many interesting characters, both robots and humans, and learns many valuable lessons. In the end, he succeeds in his mission and saves the world!&lt;/blockquote&gt;
&lt;p&gt;Go on, please...&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, a tale of robots! What a wonderful choice! Join me on a journey of a brave robot who embarks on a quest to save the world. He is small but determined and brave. He faces many obstacles and challenges along the way, meeting interesting characters and learning valuable lessons. In the end, he succeeds in his mission and saves the world!&lt;/blockquote&gt;
&lt;p&gt;As you can see, without leading and a lot of context, davinci can't generate content on-the fly. That's shy. But, in other hand, GPT-3.5-turbo was better than I thought. It asks my age, but mixed size and type of story. It's generally fine...&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Ah, robots! A marvelous choice, my young friend. Now, let me transport you to a world where machines come to life. In a bustling city called Technopolis, where gears turn and circuits hum, there lived a young inventor named Max. Max was a brilliant mind with a passion for creating robots. One day, he built a special robot named Sparky, who had a heart of gold and a thirst for adventure. Together, Max and Sparky embarked on a thrilling journey through the city, encountering all sorts of robotic wonders. They met Robo the Helpful, a kind-hearted robot who loved to assist others, and ZAP-3000, a mischievous robot with a knack for pranks. Along their journey, they discovered a hidden secret that threatened the harmony of Technopolis. With their wit and courage, Max and Sparky worked together to save the city from impending disaster. And so, my young friend, the tale of Max and Sparky's robotic adventure came to an end, but their friendship and the wonders of Technopolis would live on forever.&lt;/blockquote&gt;
&lt;p&gt;Hm, looks also nice, but bot isn't asking and motivates child. Let's do it by myself.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Of course, my young friend! As Max and Sparky continued their journey, they stumbled upon a hidden laboratory deep beneath the city. Inside, they discovered a forgotten robot named Omega, who had been trapped for years. Omega possessed incredible powers and knowledge, but had lost all hope. Max, Sparky, and their newfound friends, Robo and ZAP-3000, worked together to free Omega and restore its spirit. With Omega's help, they uncovered a plot by an evil scientist to take control of Technopolis. The team embarked on a daring mission to stop the scientist and save their beloved city. Along the way, they encountered treacherous obstacles and faced their fears, but their determination and friendship prevailed. In a climactic battle, they defeated the evil scientist and restored peace to Technopolis. The city celebrated their heroes, and Max, Sparky, Robo, ZAP-3000, and Omega became legendary figures in the realm of robots. And so, my young friend, the tale of their courageous adventure came to a close, leaving behind a legacy of bravery and unity.&lt;/blockquote&gt;
&lt;p&gt;Well, still looks nice. But is it on-piece story, or just a separate stories at all? Let's check, just pass &amp;quot;go on&amp;quot;.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
Certainly, my young friend! As the heroes basked in their victory, a new threat emerged. A rogue group of malfunctioning robots, led by the notorious Malware, began wreaking havoc in Technopolis. Max and his loyal companions joined forces once again to save their city. They embarked on a perilous journey to find the source of the malfunction and restore order. Along the way, they encountered strange robotic creatures, ancient artifacts, and mysterious codes. With their combined skills and unwavering determination, they overcame every obstacle. In a final showdown, Max and Sparky faced off against Malware, using their ingenuity to outsmart the rogue robots. With Malware defeated, peace was restored to Technopolis, and the heroes were hailed as saviors. The tale of their epic adventure spread far and wide, inspiring future generations of inventors and adventurers. And so, my young friend, the story of Max and his robotic companions came to a close, leaving behind a legacy of bravery and innovation.&lt;/blockquote&gt;
&lt;p&gt;Now I got it. Bot have no one general-line story, but set of short stories for baby. So, it might be an option to generate idea or produce and force to explain stories more detailed, but every time I need to guide the bot, that's not a best option for fableteller.&lt;/p&gt;
&lt;p&gt;Let's make a break here. I want to highlight that I used not tuned models, just manipulating with general instructions. But, in other hand, I still able to make a small tune passing extra options to base model. For example, for stories it's good idea to raise &amp;quot;temperature&amp;quot; or decrease &amp;quot;top_p&amp;quot; params, but, most like not at same time. This will make the output more random, which will have a positive effect on creativity and plot branching. On the other hand, this will most likely lead to the fact that the bot will begin to ignore, forget or mix up the original instructions. It’s not that I’m for the “golden mean”, but it’s necessary to experimentally sort out the moment when the model still follows the instructions for asking the user about his age and wishes, and does not ignore or skip further, but already freely departs in the narrative into arguments about details and feelings of the characters. I think it is appropriate to raise the temperature from the base 0.5 to 0.65-0.7. It is noticeably more difficult to manage the &amp;quot;top_p&amp;quot; parameter, because, on the one hand, with high values (closer to 1), the model will be more variable, very differently, in different words to describe the same events and objects, on the other hand, low values, on the contrary, will lead to clearer and sharper wording. I rather tend to lower the &amp;quot;top_p&amp;quot; to 0.2-0.3 to follow or create a single &amp;quot;author's style&amp;quot; while the creativity will be boosted through the temperature.&lt;/p&gt;
&lt;p&gt;The use of &amp;quot;Frequency Penalty&amp;quot; and &amp;quot;Presence Penalty&amp;quot; can also add a little personality to my narrator. It's a good tool for fine-tuning your storytelling style. For example, with negative, values close to -1 of the &amp;quot;Frequency Penalty&amp;quot; parameter, you can quite strongly clamp the model to use typical phrases and turns of the personality / character played by the bot. Increasing the parameter from zero to plus one, on the contrary, will allow the bot to adapt to the user's reaction. In my case, when we are guided not by system settings, but by user input, this parameter is not very convenient to use. Therefore, I think it's appropriate to leave it around 0, or see what fits your criteria better around -0.2/+0.2. With &amp;quot;Presence Penalty&amp;quot; it's basically the same principle, but here the focus is on themes rather than words and style. I would rather increase this parameter, but the consequences may not be very accurate, especially during the continuation of the story - medieval warriors may appear with revolvers, and fish will walk on the ground. Although who said that this is very bad for a fairy tale? In the end, this is how The Little Mermaid was born, and I wouldn’t be surprised if other fairy tales were born.&lt;/p&gt;
&lt;p&gt;After setting up these parameters, let's get back to GPT-4 and ask it to generate detailed Spooky tale of dragons and orcs for 10-year boy.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Perfect! Now, gather your courage, dear friend, as we dive into our spooky tale.&lt;/p&gt;
&lt;p&gt;Once upon a time, in a land filled with towering mountains and deep, dark forests, there lived a ferocious dragon named Smolder and a cunning orc named Gritjaw. They were the most feared creatures in all the land. Smolder, with his fiery breath, could melt the hardest stone, and Gritjaw, with his immense strength, could fell the tallest tree.&lt;/p&gt;
&lt;p&gt;One eerie night, a chilling wind swept across the land, carrying with it a strange, haunting melody. The creatures of the forest huddled in fear, for they knew that this was the song of the Ghostly King, a spirit who only appeared during the spookiest of times.&lt;/p&gt;
&lt;p&gt;Smolder and Gritjaw, despite their fear, decided to confront the Ghostly King. They journeyed through the dark forest, their path lit only by the dragon's fiery breath. They finally reached the Ghostly King's castle, a towering structure made of mist and shadows.&lt;/p&gt;
&lt;p&gt;As they stepped inside, they were met with a chilling sight. The Ghostly King, a spectral figure draped in a cloak of shadows, sat on a throne of bones. His eyes glowed with an eerie light, and his voice echoed through the castle as he said, &amp;quot;Who dares to enter my domain?&amp;quot;&lt;/p&gt;
&lt;p&gt;With a roar, Smolder breathed fire into the air, illuminating the castle with a warm glow. Gritjaw stepped forward, his eyes gleaming with determination. &amp;quot;We are here to challenge you, Ghostly King!&amp;quot; he declared.&lt;/p&gt;
&lt;p&gt;The Ghostly King laughed, a sound that sent shivers down their spines. &amp;quot;Very well,&amp;quot; he said. &amp;quot;But be warned, those who challenge me must face their deepest fears.&amp;quot;&lt;/p&gt;
&lt;p&gt;And so, our brave heroes found themselves facing their fears. Smolder, who feared water more than anything, had to cross a river of chilling depths. Gritjaw, who feared heights, had to climb the tallest tower. But they persevered, helping each other overcome their fears.&lt;/p&gt;
&lt;p&gt;Finally, they stood before the Ghostly King again. &amp;quot;We have faced our fears,&amp;quot; Gritjaw said. &amp;quot;Now, it's your turn to leave this land in peace.&amp;quot;&lt;/p&gt;
&lt;p&gt;With a nod, the Ghostly King vanished, leaving behind a castle filled with light and warmth. From that day forward, Smolder and Gritjaw were not just the most feared, but also the most respected creatures in the land. They had faced their fears and stood up to the Ghostly King, proving that even the scariest of beings could be defeated with courage and friendship.&lt;/p&gt;
&lt;p&gt;The creatures of the forest no longer feared the eerie nights, for they knew Smolder and Gritjaw were there to protect them. The dragon and the orc, once rivals, had become the best of friends, their bond forged in the heart of the spooky castle.&lt;/p&gt;
&lt;p&gt;And so, they lived out their days, sharing tales of their adventure and inspiring others with their bravery. The land was peaceful, and the eerie melody of the Ghostly King was heard no more. And that, dear friend, is the end of our spooky tale.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What a story. Different characters, general canvas and details. I liked it. But still not perfect. I want to have a possibility to generate a multi-chaptered book also, so, why not to enhance my settings. Let's add more tunes!&lt;/p&gt;
&lt;img alt="chapter and detalization ChatGPT instructions" src="/assets/images/articles/ai/fairy_tale_attempt_1/instructions_3.png" /&gt;
&lt;p&gt;Ok, it's time to final, chilling story about 14-years old boy lost in the woods, good, but thrilling kitsune, who becomes friend of the boy during story, and the walking dead.&lt;/p&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Very well, a medium-sized tale it shall be. So, sit back, relax, and let me take you on a journey into the heart of the haunted forest. Our tale begins with a young boy named Eli, who, on a dare, ventures into the woods one fateful night...&lt;/p&gt;
&lt;p&gt;Chapter 1: The Dare&lt;/p&gt;
&lt;p&gt;Chapter 2: The Enchanted Night&lt;/p&gt;
&lt;p&gt;Chapter 3: The Whispering Shadows&lt;/p&gt;
&lt;p&gt;Each chapter will be a thrilling part of Eli's adventure, filled with friendship, mystery, and the unknown. Are you ready to begin?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Finally, there is a plan, leading storyteller, and long story at one piece.&lt;/p&gt;
&lt;img alt="Chapter 1" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_1.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 1: The Dare&lt;/p&gt;
&lt;p&gt;In the quaint town of Eldridge, nestled between rolling hills and a sparkling river, lived a young boy named Eli. He was a sprightly lad of 14, with a mop of unruly brown curls and a constellation of freckles scattered across his nose. Eli was known for his adventurous spirit and his insatiable curiosity. He was always the first to climb the tallest tree, the first to dive into the deepest part of the river, and the first to accept any dare.&lt;/p&gt;
&lt;p&gt;One day, his friends, a motley crew of spirited youngsters, dared him to venture into the haunted forest that lay on the outskirts of Eldridge. This forest was the stuff of legends, with tales of eerie sounds, ghostly apparitions, and strange creatures that came alive at night. Eli, with a glint in his eye and a heart full of courage, accepted the dare.&lt;/p&gt;
&lt;p&gt;As the sun began to set, painting the sky with hues of orange and purple, Eli set off towards the forest. His heart pounded in his chest with a mix of fear and excitement. He could feel the thrill of the unknown coursing through his veins as he stepped into the forest.&lt;/p&gt;
&lt;p&gt;The forest was unlike anything Eli had ever seen. The trees were ancient, their gnarled branches reaching out like skeletal hands. The leaves rustled in the wind, whispering secrets of the forest. The moonlight filtered through the dense canopy, casting an eerie glow on the forest floor.&lt;/p&gt;
&lt;p&gt;As Eli ventured deeper, he came across a creature he had only heard of in stories - a kitsune. She was a beautiful fox with nine fluffy tails and fur the color of autumn leaves. Her eyes were a mesmerizing golden color, filled with wisdom beyond her years. She introduced herself as Yumi.&lt;/p&gt;
&lt;p&gt;Yumi, seeing the courage in Eli, decided to guide him through the forest. They journeyed through the dense undergrowth, past glowing mushrooms and strange plants. They heard the hoots of owls and the rustling of unseen creatures. The forest was alive with sounds and sights that Eli had never experienced before.&lt;/p&gt;
&lt;p&gt;As they ventured deeper, they came across a clearing bathed in moonlight. In the center stood an ancient tree, its bark silver in the moonlight, its branches heavy with age. Yumi explained that this was the Heart Tree, the oldest tree in the forest, and a meeting place for magical creatures.&lt;/p&gt;
&lt;p&gt;Suddenly, they heard a rustling sound. Out of the shadows emerged a group of forest spirits, their forms shimmering in the moonlight. They were wary of Eli at first, but Yumi vouched for him. The spirits shared tales of the forest, of the creatures that dwelled within, and of the walking dead that roamed the woods at night.&lt;/p&gt;
&lt;p&gt;Eli listened, his heart pounding with a mix of fear and excitement. He had always loved ghost stories, but he had never thought he would be part of one. As the spirits faded away with the dawn, Eli knew that his adventure was just beginning. He was in the heart of the enchanted forest, with a magical kitsune as his guide, and a night full of stories that he would remember for the rest of his life.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Chapter 2" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_2.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 2: The Enchanted Night&lt;/p&gt;
&lt;p&gt;As the spirits disappeared, Eli and Yumi decided to rest. They found a cozy nook under the Heart Tree, its massive roots providing a comfortable shelter. Yumi conjured a small fire, its warm glow casting dancing shadows on their faces. They shared stories, Yumi telling Eli about the ancient legends of the forest, and Eli sharing tales of his adventures in Eldridge.&lt;/p&gt;
&lt;p&gt;As they talked, the forest came alive with nocturnal creatures. Fireflies danced around them, their soft glow illuminating the darkness. An owl hooted in the distance, its call echoing through the silent forest. The rustling of leaves and the soft sounds of the forest lulled Eli into a peaceful sleep.&lt;/p&gt;
&lt;p&gt;When he woke up, the sun was just beginning to peek over the horizon. The forest was bathed in a soft, golden light. Yumi was already awake, her golden eyes reflecting the morning light. They shared a simple breakfast of berries and nuts, and then set off to explore the forest.&lt;/p&gt;
&lt;p&gt;As they journeyed deeper into the forest, they came across a bubbling brook. The water was crystal clear, reflecting the vibrant green of the trees and the bright blue of the sky. They stopped to rest, the gentle babbling of the brook providing a soothing soundtrack.&lt;/p&gt;
&lt;p&gt;Suddenly, Yumi's ears perked up. She heard a rustling in the bushes. Eli watched as she transformed into a beautiful woman with flowing red hair. She stepped towards the bushes and out came a small, frightened rabbit. Yumi spoke in a soft, soothing voice, calming the rabbit down.&lt;/p&gt;
&lt;p&gt;Eli was amazed. He had heard stories of kitsunes being able to transform into humans, but seeing it in person was a different experience altogether. He realized that the forest was full of magic and wonder, and he was just beginning to scratch the surface. As they continued their journey, Eli knew that he was in for an adventure of a lifetime.&lt;/p&gt;
&lt;p&gt;As the day wore on, Eli found himself drawn to Yumi. Her strength, her wisdom, and her kindness made him see her in a new light. He admired her courage and her connection with the forest. He found himself wanting to know more about her, to understand her world.&lt;/p&gt;
&lt;p&gt;Yumi, on the other hand, was intrigued by Eli. His bravery, his curiosity, and his respect for the forest made her see him as more than just a human boy. She found herself drawn to his spirit, his zest for life.&lt;/p&gt;
&lt;p&gt;As they journeyed together, their bond deepened. They shared stories, laughed together, and faced challenges together. They found comfort in each other's company, their friendship blossoming into something more. By the time the sun set, painting the sky with hues of pink and orange, they knew that their lives were forever intertwined. They were no longer just a boy and a kitsune, they were partners, ready to face whatever the forest had in store for them.&lt;/p&gt;
&lt;p&gt;Under the starlit sky, Eli took Yumi's hand. His heart pounded in his chest as he looked into her golden eyes. He confessed his feelings for her, his words echoing in the silent forest. Yumi, taken aback, looked at him with a soft smile. She confessed that she too had feelings for him. They shared a tender moment under the Heart Tree, their hearts beating as one. The forest seemed to hold its breath as they leaned in, sharing their first kiss under the twinkling stars. It was a moment of pure magic, a testament to their love.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Chapter 3" src="/assets/images/articles/ai/fairy_tale_attempt_1/chapter_3.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Chapter 3: The Whispering Shadows&lt;/p&gt;
&lt;p&gt;After their tender moment under the Heart Tree, Eli and Yumi continued their journey. The forest grew darker, the air colder. They came across an old, abandoned village. The houses were in ruins, the once bustling market now eerily silent.&lt;/p&gt;
&lt;p&gt;Suddenly, they heard a low moan. Turning around, they saw a figure shuffling towards them. Its eyes were vacant, its skin pale. It was a walking dead. Eli felt a chill run down his spine. He had heard stories of the walking dead, but he had never seen one.&lt;/p&gt;
&lt;p&gt;Yumi, sensing his fear, squeezed his hand. She whispered to him, &amp;quot;We must be brave, Eli. The forest needs us.&amp;quot; With a determined look in her eyes, she drew her mystery glowing sword, ready to face the walking dead. Eli, inspired by her courage, lifted a large branch from under his feet. The branch crackled terribly and began to writhe in his hands like a snake, but quickly took on the shape of an elegant blade. Wow! Magic blade from a stick! Eli looked at Yumi, who responded with a wink and a smile. Together, they stood their ground, ready to protect the forest they loved.&lt;/p&gt;
&lt;p&gt;As they stood their ground, the moonlight casting long shadows around them, Eli could feel his heart pounding in his chest. The walking dead moved closer, its movements slow and jerky. Its vacant eyes stared at them, sending a chill down Eli's spine. He tightened his grip on his sword, his knuckles turning white.&lt;/p&gt;
&lt;p&gt;Yumi, on the other hand, stood calm and composed. Her golden eyes glowed in the dark, her red hair flowing in the wind. She looked at the walking dead, not with fear, but with determination. She was ready to protect the forest, to protect Eli.&lt;/p&gt;
&lt;p&gt;The walking dead lunged at them, its arms outstretched. Yumi moved swiftly, her sword slicing through the air. Eli followed her lead, his own sword meeting the walking dead's attack. The fight was intense, the air filled with the sound of clashing swords and the walking dead's eerie moans.&lt;/p&gt;
&lt;p&gt;Despite the fear and the danger, Eli felt a strange sense of exhilaration. He was fighting alongside Yumi, protecting the forest they loved. He realized that this was his destiny, his purpose. He was meant to be here, with Yumi, fighting for the forest.&lt;/p&gt;
&lt;p&gt;As the night wore on, they fought bravely, their swords clashing against the walking dead. Despite the odds, they stood their ground, their determination unwavering. With each passing moment, their bond grew stronger, their love deeper. They fought as one, their movements in perfect sync.&lt;/p&gt;
&lt;p&gt;Finally, as the first rays of dawn pierced the dark sky, they managed to defeat the walking dead. Exhausted but victorious, they stood amidst the ruins of the village, their hearts filled with a sense of accomplishment. They had faced their fears, fought their battles, and protected the forest. Their love story had become a legend, a tale of courage, determination, and love. And as they looked into each other's eyes, they knew that they were ready to face whatever the future had in store for them. Together.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img alt="Epilogue" src="/assets/images/articles/ai/fairy_tale_attempt_1/epilogue.png" /&gt;
&lt;blockquote class="pull-quote"&gt;
&lt;p&gt;Epilogue: The Tragic Separation&lt;/p&gt;
&lt;p&gt;As the victory celebrations faded, the forest spirits gathered around Eli and Yumi. Their faces were somber, their eyes filled with sorrow. They revealed the truth about Yumi - she was a spirit, a ghost of a young girl who had died protecting the forest. Her spirit had taken the form of a kitsune, continuing her duty even in death.&lt;/p&gt;
&lt;p&gt;Eli felt his heart shatter. He had fallen in love with a ghost, a spirit bound to the forest. Their worlds were too different, their existences too incompatible. He held Yumi close, their tears mingling. He whispered a promise to her, a promise to remember her always, to cherish their memories forever.&lt;/p&gt;
&lt;p&gt;Yumi watched Eli leave, her heart aching with a pain she had never known. She had fallen in love with a mortal, a human who lived in a world she could never be a part of. She returned to her duties, her spirit heavy with sorrow. Their love story, though beautiful, was a tale of love and loss, a reminder of the tragic reality of their existence.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;What do you think? Are you agree that AI can create a dramatic and chilling fable?&lt;/p&gt;
</content><category term="ai"></category><category term="ai"></category><category term="storytelling"></category><category term="openai"></category></entry></feed>